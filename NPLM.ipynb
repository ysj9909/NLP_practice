{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NPLM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkzKyGtf3bhwIjS08ajmwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysj9909/NLP_practice/blob/main/NPLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQT_E6TdG4TX"
      },
      "source": [
        "**Neual Probability Language Model 코드 구현 연습!!**\n",
        "\n",
        "* paper link: https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
        "\n",
        "* reference link : https://github.com/graykode/nlp-tutorial/tree/master/1-1.NNLM\n",
        "\n",
        "* Datasert : text9 corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvlamXsO6aVz"
      },
      "source": [
        "import torch\n",
        "\n",
        "f = open('text9.txt', 'r')\n",
        "words = f.read().split(' ')\n",
        "f.close()\n",
        "\n",
        "words = words[:100]\n",
        "\n",
        "word2idx = {}\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for word in words:\n",
        "  if not word in word2idx:\n",
        "    word2idx[word] = idx\n",
        "    idx += 1\n",
        "\n",
        "idx2word = {j : i for i, j in word2idx.items()}\n",
        "\n",
        "Vocabulary_size = len(word2idx)\n",
        "\n",
        "def make_batch(words, n_gram):\n",
        "  input_batch = []\n",
        "  target_batch = []\n",
        "\n",
        "  for i in range(n_gram , len(words)):\n",
        "    input = [ word2idx[word] for word in words[i - n_gram: i]]\n",
        "    target = word2idx[words[i]]\n",
        "\n",
        "    input_batch.append(input)\n",
        "    target_batch.append(target)\n",
        "  return input_batch, target_batch\n",
        "\n",
        "n_gram = 3\n",
        "hidden_dim = 50\n",
        "embed_dim = 50\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "\n",
        "input_batch, target_batch = make_batch(words, n_gram)\n",
        "input_batch = torch.LongTensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0qwtQTYSwp6",
        "outputId": "39aa83c0-3222-490c-c733-68f5a1323109"
      },
      "source": [
        "print(input_batch.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([97, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCGEe26SHL_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655c90dd-a8ba-48e2-b294-5ea55c6e60ed"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "class NNLM(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, n_gram, is_direct_connection = False):\n",
        "    super(NNLM, self).__init__()\n",
        "    self.is_direct_connection = is_direct_connection\n",
        "    self.n_gram = n_gram\n",
        "    self.embed_dim = embed_dim\n",
        "\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.fc_hidden = nn.Linear(n_gram * embed_dim, hidden_dim)\n",
        "    self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
        "    if is_direct_connection:\n",
        "      self.W = nn.Linear(n_gram * embed_dim, vocab_size)\n",
        "    self.bias = torch.zeros(vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.embedding(input) # (batch_size, n_gram, embed_dim)\n",
        "    embedded = embedded.view(-1, self.n_gram * self.embed_dim) # (batch_size, n_gram * embed_dim)\n",
        "    hidden_state = torch.tanh(self.fc_hidden(embedded))\n",
        "    if self.is_direct_connection:\n",
        "      y = nn.Parameter(self.bias) + self.W(embedded) + self.fc_out(hidden_state) \n",
        "    else:\n",
        "      y = nn.Parameter(self.bias) + self.fc_out(hidden_state)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "model = NNLM(Vocabulary_size, embed_dim, hidden_dim, n_gram, True)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  outputs = model(input_batch)\n",
        "  loss = criterion(outputs, target_batch)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    print(f\"Epoch[{epoch + 1} / {num_epochs}], Loss : {loss.item()}\")\n",
        "\n",
        "# Predict\n",
        "predicted = model(input_batch).data.max(1, keepdim = True)[1]\n",
        "\n",
        "# Test\n",
        "for i in range(5):\n",
        "  print(\"model's output : \", idx2word[int(predicted[i])],' -> ' ,\"target word : \", idx2word[int(target_batch[i])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[10 / 100], Loss : 2.9890730381011963\n",
            "Epoch[20 / 100], Loss : 1.741727352142334\n",
            "Epoch[30 / 100], Loss : 0.8934531211853027\n",
            "Epoch[40 / 100], Loss : 0.44029298424720764\n",
            "Epoch[50 / 100], Loss : 0.22925002872943878\n",
            "Epoch[60 / 100], Loss : 0.13942982256412506\n",
            "Epoch[70 / 100], Loss : 0.09908091276884079\n",
            "Epoch[80 / 100], Loss : 0.07777344435453415\n",
            "Epoch[90 / 100], Loss : 0.06488428264856339\n",
            "Epoch[100 / 100], Loss : 0.05624343082308769\n",
            "model's output :  a  ->  target word :  a\n",
            "model's output :  term  ->  target word :  term\n",
            "model's output :  of  ->  target word :  of\n",
            "model's output :  abuse  ->  target word :  abuse\n",
            "model's output :  first  ->  target word :  originated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5AiDm9xSmYH",
        "outputId": "11efe8b8-50e9-41da-bb71-0a2b209e5eae"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.zeros(3, 5)\n",
        "print(a[1].size())\n",
        "print(a[:1].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5])\n",
            "torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb6I_ZegUmeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6637bf11-9c18-47f0-8cd3-6ace001c589d"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.arange(15).view(3, 5)\n",
        "embedding = torch.nn.Embedding(20, 3)\n",
        "print(a.size())\n",
        "b = embedding(a)\n",
        "print(b.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5])\n",
            "torch.Size([3, 5, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06hPv0asT7o6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}