{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_skipgram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsgEElNivksTKg/arfdVDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysj9909/NLP_practice/blob/main/Word2Vec_skipgram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EljkWq_H4o5U"
      },
      "source": [
        "**skipgram(softmax) Model 코드 구현 연습!!**\n",
        "\n",
        "* paper link: https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\n",
        "\n",
        "* Dataset : text9 corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "with open(\"text9.txt\", \"r\") as f:\n",
        "  words = f.read().split(\" \")\n",
        "  f.close()\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyper-parameters\n",
        "window_size = 2\n",
        "embed_dim = 300\n",
        "learning_rate = 9\n",
        "num_epochs = 3\n",
        "\n",
        "word2idx = {}\n",
        "idx2word = {}\n",
        "word2freq = {}\n",
        "\n",
        "idx = 0\n",
        "for word in words:\n",
        "  if not word in word2idx:\n",
        "    word2idx[word] = idx\n",
        "    word2freq[word] = 1\n",
        "    idx2word[idx] = word\n",
        "    idx += 1\n",
        "  else:\n",
        "    word2freq[word] += 1\n",
        "\n",
        "sum = 0\n",
        "for word, freq in word2freq.items():\n",
        "  if freq <= 1:\n",
        "    word2freq[word] = 0\n",
        "  else:\n",
        "    word2freq[word] = (word2freq[word] / len(words)) ** (3 / 4)\n",
        "    sum += word2freq[word]\n",
        "vocab_size = len(word2freq)\n",
        "\n",
        "for word, freq in word2freq.items():\n",
        "  word2freq[word] /= sum\n",
        "\n",
        "def make_one_hot(idx, vocab_size):\n",
        "  one_hot = np.zeros(vocab_size)\n",
        "  one_hot[idx] = 1\n",
        "  return one_hot\n",
        "\n",
        "inputs = []\n",
        "targets = []\n",
        "for i in range(2, 10002):\n",
        "  if word2freq[words[i]] == 0:\n",
        "    continue\n",
        "  else:\n",
        "    input = [make_one_hot(word2idx[words[i]], vocab_size)] * (2 * window_size)\n",
        "    target = [word2idx[words[i + j]] for j in  range(-2, 3) if j != 0]\n",
        "    targets.append(target)\n",
        "    inputs.append(input)\n",
        "inputs, targets = torch.Tensor(inputs), torch.LongTensor(targets)\n",
        "inputs = inputs.view(-1, inputs.size(-1))\n",
        "targets = targets.view(-1)\n",
        "\n",
        "train_dataset = (inputs, targets)\n",
        "print(inputs.size())\n",
        "print(targets.size())\n",
        "\n",
        "\n",
        "class skipgram_negative_sampling(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim):\n",
        "    super(skipgram_negative_sampling, self).__init__()\n",
        "\n",
        "    self.W = nn.Linear(vocab_size, embed_dim, bias = False)\n",
        "    self.W_out = nn.Linear(embed_dim, vocab_size, bias = False)\n",
        "\n",
        "  def train(self, train_dataset, num_epochs, k = 15, window_size = 2, lr = learning_rate):   \n",
        "    inputs, targets = train_dataset\n",
        "    for epoch in range(num_epochs):\n",
        "      total_loss = 0\n",
        "      for i in range(0, len(inputs) - 100, 100):\n",
        "        W_weight = nn.Parameter(self.W.weight).to(device)\n",
        "        W_out_weight = nn.Parameter(self.W_out.weight).to(device)\n",
        "        input = inputs[i: i + 100].to(device)\n",
        "        target = targets[i : i + 100].to(device)\n",
        "\n",
        "        outputs  = self.W(input)\n",
        "        outputs = self.W_out(outputs)       # (num_training, vocab_size)\n",
        "        \n",
        "        self.W.weight.retain_grad()\n",
        "        self.W_out.weight.retain_grad()\n",
        "        \n",
        "        loss = 0\n",
        "        prediction_values = outputs[:, targets]\n",
        "        for t in range(100):\n",
        "          negative_sampled = np.random.choice(list(word2freq.keys()),size = k,  p = list(word2freq.values()))\n",
        "          negative_sampled = torch.LongTensor([word2idx[word] for word in negative_sampled])\n",
        "          loss -= torch.log(F.sigmoid(prediction_values[t, t])) + torch.sum(torch.log(F.sigmoid(-outputs[t, negative_sampled])))\n",
        "        loss /= 100\n",
        "\n",
        "        loss.backward()\n",
        "        W_weight = W_weight -lr * self.W.weight.grad\n",
        "        W_out_weight = W_out_weight - lr * self.W_out.weight.grad\n",
        "        self.W.weight, self.W_out.weight = nn.Parameter(W_weight), nn.Parameter(W_out_weight)\n",
        "        # Manully zero the gradients after updating weights\n",
        "        self.W.weight.grad = None\n",
        "        self.W_out.weight.grad = None\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1} / {num_epochs}],Step [{i} / {len(inputs)}], Loss : {loss.item()}\")\n",
        "      lr /= 3\n",
        "  \n",
        "  def compute_sim(self, word1_vec, word2_vec):\n",
        "    norm_word1 = torch.sum(word1_vec ** 2) ** (1 / 2)\n",
        "    norm_word2 = torch.sum(word2_vec ** 2) ** (1 / 2)\n",
        "    return torch.sum(word1_vec * word2_vec) / (norm_word1 * norm_word2)\n",
        "  \n",
        "  def most_similar(self, word_vec):\n",
        "    max_sim = 0\n",
        "    most_sim_word = None\n",
        "    for w, freq in word2freq.items():\n",
        "      if freq > 0:\n",
        "        w_vec = self.W(torch.Tensor(make_one_hot(word2idx[w], vocab_size)).to(device))\n",
        "        sim = self.compute_sim(word_vec, w_vec)\n",
        "        if sim > max_sim:\n",
        "           most_sim_word = w\n",
        "           max_sim = sim\n",
        "    return most_sim_word\n",
        "\n",
        "  def analogic_test(self, word1, word2, word3):\n",
        "    word1, word2, word3 = torch.Tensor(make_one_hot(word1, vocab_size)), torch.Tensor(make_one_hot(word2, vocab_size)), torch.Tensor(make_one_hot(word3, vocab_size))\n",
        "    word1_vec = self.W(word1.to(device))\n",
        "    word2_vec = self.W(word2.to(device))\n",
        "    word3_vec = self.W(word3.to(device))\n",
        "    return self.most_similar(word1_vec - word2_vec + word3_vec)\n",
        "  \n",
        "  def similar_words(self, word_id, k):\n",
        "    word_vec = self.W(torch.Tensor(make_one_hot(word_id, vocab_size)).to(device))\n",
        "    word2sim = {}\n",
        "    for w, freq in word2freq.items():\n",
        "      if freq > 0:\n",
        "        w_vec = self.W(torch.Tensor(make_one_hot(word2idx[w], vocab_size)).to(device))\n",
        "        sim = self.compute_sim(word_vec, w_vec)\n",
        "        word2sim[w] = sim\n",
        "    sim_list = sorted(word2sim.items(), key = lambda x : x[1], reverse = True)\n",
        "    return sim_list[1: k + 1]\n",
        "\n",
        "\n",
        "\n",
        "model = skipgram_negative_sampling(vocab_size, embed_dim).to(device)\n",
        "model.train(train_dataset, num_epochs)\n",
        "\n",
        "torch.save(model.state_dict(), \"word2vec_neg15_params.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Kdi0jKy04C",
        "outputId": "6f1ce1c4-1a97-4bfe-cc04-5268447c7043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([38540, 24429])\n",
            "torch.Size([38540])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 3],Step [0 / 38540], Loss : 11.09066390991211\n",
            "Epoch [1 / 3],Step [100 / 38540], Loss : 11.086169242858887\n",
            "Epoch [1 / 3],Step [200 / 38540], Loss : 11.083160400390625\n",
            "Epoch [1 / 3],Step [300 / 38540], Loss : 11.079219818115234\n",
            "Epoch [1 / 3],Step [400 / 38540], Loss : 11.068778038024902\n",
            "Epoch [1 / 3],Step [500 / 38540], Loss : 11.075840950012207\n",
            "Epoch [1 / 3],Step [600 / 38540], Loss : 11.063456535339355\n",
            "Epoch [1 / 3],Step [700 / 38540], Loss : 11.055484771728516\n",
            "Epoch [1 / 3],Step [800 / 38540], Loss : 11.054841995239258\n",
            "Epoch [1 / 3],Step [900 / 38540], Loss : 11.05109977722168\n",
            "Epoch [1 / 3],Step [1000 / 38540], Loss : 11.026481628417969\n",
            "Epoch [1 / 3],Step [1100 / 38540], Loss : 10.942771911621094\n",
            "Epoch [1 / 3],Step [1200 / 38540], Loss : 10.7358980178833\n",
            "Epoch [1 / 3],Step [1300 / 38540], Loss : 10.889676094055176\n",
            "Epoch [1 / 3],Step [1400 / 38540], Loss : 10.761174201965332\n",
            "Epoch [1 / 3],Step [1500 / 38540], Loss : 10.63432502746582\n",
            "Epoch [1 / 3],Step [1600 / 38540], Loss : 10.517623901367188\n",
            "Epoch [1 / 3],Step [1700 / 38540], Loss : 10.772148132324219\n",
            "Epoch [1 / 3],Step [1800 / 38540], Loss : 10.403382301330566\n",
            "Epoch [1 / 3],Step [1900 / 38540], Loss : 10.273090362548828\n",
            "Epoch [1 / 3],Step [2000 / 38540], Loss : 10.291404724121094\n",
            "Epoch [1 / 3],Step [2100 / 38540], Loss : 9.94119930267334\n",
            "Epoch [1 / 3],Step [2200 / 38540], Loss : 10.00723648071289\n",
            "Epoch [1 / 3],Step [2300 / 38540], Loss : 9.721088409423828\n",
            "Epoch [1 / 3],Step [2400 / 38540], Loss : 9.532601356506348\n",
            "Epoch [1 / 3],Step [2500 / 38540], Loss : 9.594232559204102\n",
            "Epoch [1 / 3],Step [2600 / 38540], Loss : 9.827116966247559\n",
            "Epoch [1 / 3],Step [2700 / 38540], Loss : 9.604272842407227\n",
            "Epoch [1 / 3],Step [2800 / 38540], Loss : 9.559874534606934\n",
            "Epoch [1 / 3],Step [2900 / 38540], Loss : 9.667115211486816\n",
            "Epoch [1 / 3],Step [3000 / 38540], Loss : 9.244382858276367\n",
            "Epoch [1 / 3],Step [3100 / 38540], Loss : 8.459134101867676\n",
            "Epoch [1 / 3],Step [3200 / 38540], Loss : 9.365823745727539\n",
            "Epoch [1 / 3],Step [3300 / 38540], Loss : 8.783352851867676\n",
            "Epoch [1 / 3],Step [3400 / 38540], Loss : 8.388243675231934\n",
            "Epoch [1 / 3],Step [3500 / 38540], Loss : 8.371328353881836\n",
            "Epoch [1 / 3],Step [3600 / 38540], Loss : 9.18367862701416\n",
            "Epoch [1 / 3],Step [3700 / 38540], Loss : 8.851993560791016\n",
            "Epoch [1 / 3],Step [3800 / 38540], Loss : 8.709795951843262\n",
            "Epoch [1 / 3],Step [3900 / 38540], Loss : 9.566900253295898\n",
            "Epoch [1 / 3],Step [4000 / 38540], Loss : 9.338143348693848\n",
            "Epoch [1 / 3],Step [4100 / 38540], Loss : 7.31104040145874\n",
            "Epoch [1 / 3],Step [4200 / 38540], Loss : 7.795661449432373\n",
            "Epoch [1 / 3],Step [4300 / 38540], Loss : 8.240689277648926\n",
            "Epoch [1 / 3],Step [4400 / 38540], Loss : 7.713761329650879\n",
            "Epoch [1 / 3],Step [4500 / 38540], Loss : 7.729427337646484\n",
            "Epoch [1 / 3],Step [4600 / 38540], Loss : 7.527267932891846\n",
            "Epoch [1 / 3],Step [4700 / 38540], Loss : 8.226886749267578\n",
            "Epoch [1 / 3],Step [4800 / 38540], Loss : 7.307968616485596\n",
            "Epoch [1 / 3],Step [4900 / 38540], Loss : 7.245163917541504\n",
            "Epoch [1 / 3],Step [5000 / 38540], Loss : 8.853690147399902\n",
            "Epoch [1 / 3],Step [5100 / 38540], Loss : 7.75606632232666\n",
            "Epoch [1 / 3],Step [5200 / 38540], Loss : 7.821063041687012\n",
            "Epoch [1 / 3],Step [5300 / 38540], Loss : 7.42453670501709\n",
            "Epoch [1 / 3],Step [5400 / 38540], Loss : 7.8860321044921875\n",
            "Epoch [1 / 3],Step [5500 / 38540], Loss : 6.863713264465332\n",
            "Epoch [1 / 3],Step [5600 / 38540], Loss : 8.196441650390625\n",
            "Epoch [1 / 3],Step [5700 / 38540], Loss : 7.213023662567139\n",
            "Epoch [1 / 3],Step [5800 / 38540], Loss : 7.364592552185059\n",
            "Epoch [1 / 3],Step [5900 / 38540], Loss : 7.716552734375\n",
            "Epoch [1 / 3],Step [6000 / 38540], Loss : 8.296588897705078\n",
            "Epoch [1 / 3],Step [6100 / 38540], Loss : 6.842244625091553\n",
            "Epoch [1 / 3],Step [6200 / 38540], Loss : 7.831313133239746\n",
            "Epoch [1 / 3],Step [6300 / 38540], Loss : 6.612246513366699\n",
            "Epoch [1 / 3],Step [6400 / 38540], Loss : 6.7411088943481445\n",
            "Epoch [1 / 3],Step [6500 / 38540], Loss : 6.167856693267822\n",
            "Epoch [1 / 3],Step [6600 / 38540], Loss : 7.081953525543213\n",
            "Epoch [1 / 3],Step [6700 / 38540], Loss : 7.456197738647461\n",
            "Epoch [1 / 3],Step [6800 / 38540], Loss : 6.733527660369873\n",
            "Epoch [1 / 3],Step [6900 / 38540], Loss : 6.642652988433838\n",
            "Epoch [1 / 3],Step [7000 / 38540], Loss : 6.652202129364014\n",
            "Epoch [1 / 3],Step [7100 / 38540], Loss : 7.612039566040039\n",
            "Epoch [1 / 3],Step [7200 / 38540], Loss : 5.561491966247559\n",
            "Epoch [1 / 3],Step [7300 / 38540], Loss : 5.470731258392334\n",
            "Epoch [1 / 3],Step [7400 / 38540], Loss : 7.916530609130859\n",
            "Epoch [1 / 3],Step [7500 / 38540], Loss : 7.243779182434082\n",
            "Epoch [1 / 3],Step [7600 / 38540], Loss : 5.788435459136963\n",
            "Epoch [1 / 3],Step [7700 / 38540], Loss : 6.1175713539123535\n",
            "Epoch [1 / 3],Step [7800 / 38540], Loss : 7.5331130027771\n",
            "Epoch [1 / 3],Step [7900 / 38540], Loss : 6.904673099517822\n",
            "Epoch [1 / 3],Step [8000 / 38540], Loss : 5.987363338470459\n",
            "Epoch [1 / 3],Step [8100 / 38540], Loss : 5.905766487121582\n",
            "Epoch [1 / 3],Step [8200 / 38540], Loss : 5.226539611816406\n",
            "Epoch [1 / 3],Step [8300 / 38540], Loss : 6.723376274108887\n",
            "Epoch [1 / 3],Step [8400 / 38540], Loss : 4.975549697875977\n",
            "Epoch [1 / 3],Step [8500 / 38540], Loss : 6.13572883605957\n",
            "Epoch [1 / 3],Step [8600 / 38540], Loss : 8.802814483642578\n",
            "Epoch [1 / 3],Step [8700 / 38540], Loss : 5.8269219398498535\n",
            "Epoch [1 / 3],Step [8800 / 38540], Loss : 6.468344688415527\n",
            "Epoch [1 / 3],Step [8900 / 38540], Loss : 6.278229713439941\n",
            "Epoch [1 / 3],Step [9000 / 38540], Loss : 8.218343734741211\n",
            "Epoch [1 / 3],Step [9100 / 38540], Loss : 4.896946430206299\n",
            "Epoch [1 / 3],Step [9200 / 38540], Loss : 4.199008941650391\n",
            "Epoch [1 / 3],Step [9300 / 38540], Loss : 6.692327499389648\n",
            "Epoch [1 / 3],Step [9400 / 38540], Loss : 7.1571946144104\n",
            "Epoch [1 / 3],Step [9500 / 38540], Loss : 5.87357759475708\n",
            "Epoch [1 / 3],Step [9600 / 38540], Loss : 5.580729961395264\n",
            "Epoch [1 / 3],Step [9700 / 38540], Loss : 4.7652997970581055\n",
            "Epoch [1 / 3],Step [9800 / 38540], Loss : 5.535765647888184\n",
            "Epoch [1 / 3],Step [9900 / 38540], Loss : 6.50311279296875\n",
            "Epoch [1 / 3],Step [10000 / 38540], Loss : 5.169532775878906\n",
            "Epoch [1 / 3],Step [10100 / 38540], Loss : 6.799914360046387\n",
            "Epoch [1 / 3],Step [10200 / 38540], Loss : 4.258274555206299\n",
            "Epoch [1 / 3],Step [10300 / 38540], Loss : 5.818608283996582\n",
            "Epoch [1 / 3],Step [10400 / 38540], Loss : 7.9660539627075195\n",
            "Epoch [1 / 3],Step [10500 / 38540], Loss : 6.421387195587158\n",
            "Epoch [1 / 3],Step [10600 / 38540], Loss : 6.457162380218506\n",
            "Epoch [1 / 3],Step [10700 / 38540], Loss : 6.578031063079834\n",
            "Epoch [1 / 3],Step [10800 / 38540], Loss : 6.281218528747559\n",
            "Epoch [1 / 3],Step [10900 / 38540], Loss : 5.597496032714844\n",
            "Epoch [1 / 3],Step [11000 / 38540], Loss : 5.571640491485596\n",
            "Epoch [1 / 3],Step [11100 / 38540], Loss : 4.499504089355469\n",
            "Epoch [1 / 3],Step [11200 / 38540], Loss : 6.853339195251465\n",
            "Epoch [1 / 3],Step [11300 / 38540], Loss : 3.983206033706665\n",
            "Epoch [1 / 3],Step [11400 / 38540], Loss : 5.404052734375\n",
            "Epoch [1 / 3],Step [11500 / 38540], Loss : 6.289385795593262\n",
            "Epoch [1 / 3],Step [11600 / 38540], Loss : 7.164053916931152\n",
            "Epoch [1 / 3],Step [11700 / 38540], Loss : 4.184897422790527\n",
            "Epoch [1 / 3],Step [11800 / 38540], Loss : 6.459036827087402\n",
            "Epoch [1 / 3],Step [11900 / 38540], Loss : 7.7605719566345215\n",
            "Epoch [1 / 3],Step [12000 / 38540], Loss : 6.410621166229248\n",
            "Epoch [1 / 3],Step [12100 / 38540], Loss : 5.157958030700684\n",
            "Epoch [1 / 3],Step [12200 / 38540], Loss : 5.544075965881348\n",
            "Epoch [1 / 3],Step [12300 / 38540], Loss : 5.477834224700928\n",
            "Epoch [1 / 3],Step [12400 / 38540], Loss : 4.937337398529053\n",
            "Epoch [1 / 3],Step [12500 / 38540], Loss : 5.4232587814331055\n",
            "Epoch [1 / 3],Step [12600 / 38540], Loss : 5.978471755981445\n",
            "Epoch [1 / 3],Step [12700 / 38540], Loss : 4.677303791046143\n",
            "Epoch [1 / 3],Step [12800 / 38540], Loss : 5.814551830291748\n",
            "Epoch [1 / 3],Step [12900 / 38540], Loss : 4.494491100311279\n",
            "Epoch [1 / 3],Step [13000 / 38540], Loss : 5.729455947875977\n",
            "Epoch [1 / 3],Step [13100 / 38540], Loss : 5.519713401794434\n",
            "Epoch [1 / 3],Step [13200 / 38540], Loss : 4.805169582366943\n",
            "Epoch [1 / 3],Step [13300 / 38540], Loss : 7.2161102294921875\n",
            "Epoch [1 / 3],Step [13400 / 38540], Loss : 6.162882328033447\n",
            "Epoch [1 / 3],Step [13500 / 38540], Loss : 6.54919958114624\n",
            "Epoch [1 / 3],Step [13600 / 38540], Loss : 5.024251937866211\n",
            "Epoch [1 / 3],Step [13700 / 38540], Loss : 4.9359540939331055\n",
            "Epoch [1 / 3],Step [13800 / 38540], Loss : 5.663158416748047\n",
            "Epoch [1 / 3],Step [13900 / 38540], Loss : 6.557015419006348\n",
            "Epoch [1 / 3],Step [14000 / 38540], Loss : 4.0162272453308105\n",
            "Epoch [1 / 3],Step [14100 / 38540], Loss : 5.297148704528809\n",
            "Epoch [1 / 3],Step [14200 / 38540], Loss : 4.269410133361816\n",
            "Epoch [1 / 3],Step [14300 / 38540], Loss : 4.778876304626465\n",
            "Epoch [1 / 3],Step [14400 / 38540], Loss : 5.295600414276123\n",
            "Epoch [1 / 3],Step [14500 / 38540], Loss : 6.087320327758789\n",
            "Epoch [1 / 3],Step [14600 / 38540], Loss : 4.93314790725708\n",
            "Epoch [1 / 3],Step [14700 / 38540], Loss : 6.3874406814575195\n",
            "Epoch [1 / 3],Step [14800 / 38540], Loss : 5.280866622924805\n",
            "Epoch [1 / 3],Step [14900 / 38540], Loss : 4.703132629394531\n",
            "Epoch [1 / 3],Step [15000 / 38540], Loss : 4.380683422088623\n",
            "Epoch [1 / 3],Step [15100 / 38540], Loss : 6.03980016708374\n",
            "Epoch [1 / 3],Step [15200 / 38540], Loss : 6.065046310424805\n",
            "Epoch [1 / 3],Step [15300 / 38540], Loss : 4.690211772918701\n",
            "Epoch [1 / 3],Step [15400 / 38540], Loss : 3.9762303829193115\n",
            "Epoch [1 / 3],Step [15500 / 38540], Loss : 4.817056655883789\n",
            "Epoch [1 / 3],Step [15600 / 38540], Loss : 4.47369909286499\n",
            "Epoch [1 / 3],Step [15700 / 38540], Loss : 5.293603420257568\n",
            "Epoch [1 / 3],Step [15800 / 38540], Loss : 3.3914647102355957\n",
            "Epoch [1 / 3],Step [15900 / 38540], Loss : 4.008037567138672\n",
            "Epoch [1 / 3],Step [16000 / 38540], Loss : 5.670330047607422\n",
            "Epoch [1 / 3],Step [16100 / 38540], Loss : 5.847702980041504\n",
            "Epoch [1 / 3],Step [16200 / 38540], Loss : 4.032276630401611\n",
            "Epoch [1 / 3],Step [16300 / 38540], Loss : 3.7932331562042236\n",
            "Epoch [1 / 3],Step [16400 / 38540], Loss : 6.103876113891602\n",
            "Epoch [1 / 3],Step [16500 / 38540], Loss : 6.288685321807861\n",
            "Epoch [1 / 3],Step [16600 / 38540], Loss : 4.627740859985352\n",
            "Epoch [1 / 3],Step [16700 / 38540], Loss : 4.689717769622803\n",
            "Epoch [1 / 3],Step [16800 / 38540], Loss : 4.9214863777160645\n",
            "Epoch [1 / 3],Step [16900 / 38540], Loss : 3.687711477279663\n",
            "Epoch [1 / 3],Step [17000 / 38540], Loss : 6.247953414916992\n",
            "Epoch [1 / 3],Step [17100 / 38540], Loss : 6.116667747497559\n",
            "Epoch [1 / 3],Step [17200 / 38540], Loss : 5.058988094329834\n",
            "Epoch [1 / 3],Step [17300 / 38540], Loss : 4.102863311767578\n",
            "Epoch [1 / 3],Step [17400 / 38540], Loss : 4.359321594238281\n",
            "Epoch [1 / 3],Step [17500 / 38540], Loss : 4.618840217590332\n",
            "Epoch [1 / 3],Step [17600 / 38540], Loss : 4.135560989379883\n",
            "Epoch [1 / 3],Step [17700 / 38540], Loss : 5.545679092407227\n",
            "Epoch [1 / 3],Step [17800 / 38540], Loss : 3.4494924545288086\n",
            "Epoch [1 / 3],Step [17900 / 38540], Loss : 4.121758460998535\n",
            "Epoch [1 / 3],Step [18000 / 38540], Loss : 4.805110931396484\n",
            "Epoch [1 / 3],Step [18100 / 38540], Loss : 5.151413440704346\n",
            "Epoch [1 / 3],Step [18200 / 38540], Loss : 5.177858829498291\n",
            "Epoch [1 / 3],Step [18300 / 38540], Loss : 4.670129299163818\n",
            "Epoch [1 / 3],Step [18400 / 38540], Loss : 5.4493513107299805\n",
            "Epoch [1 / 3],Step [18500 / 38540], Loss : 5.099148273468018\n",
            "Epoch [1 / 3],Step [18600 / 38540], Loss : 5.0118207931518555\n",
            "Epoch [1 / 3],Step [18700 / 38540], Loss : 3.8310704231262207\n",
            "Epoch [1 / 3],Step [18800 / 38540], Loss : 3.5338494777679443\n",
            "Epoch [1 / 3],Step [18900 / 38540], Loss : 5.675963401794434\n",
            "Epoch [1 / 3],Step [19000 / 38540], Loss : 6.462168216705322\n",
            "Epoch [1 / 3],Step [19100 / 38540], Loss : 7.095254898071289\n",
            "Epoch [1 / 3],Step [19200 / 38540], Loss : 6.057253837585449\n",
            "Epoch [1 / 3],Step [19300 / 38540], Loss : 5.504636764526367\n",
            "Epoch [1 / 3],Step [19400 / 38540], Loss : 5.222253799438477\n",
            "Epoch [1 / 3],Step [19500 / 38540], Loss : 3.5703117847442627\n",
            "Epoch [1 / 3],Step [19600 / 38540], Loss : 5.129461765289307\n",
            "Epoch [1 / 3],Step [19700 / 38540], Loss : 5.050721168518066\n",
            "Epoch [1 / 3],Step [19800 / 38540], Loss : 4.154860496520996\n",
            "Epoch [1 / 3],Step [19900 / 38540], Loss : 4.533217906951904\n",
            "Epoch [1 / 3],Step [20000 / 38540], Loss : 4.5398383140563965\n",
            "Epoch [1 / 3],Step [20100 / 38540], Loss : 5.560397148132324\n",
            "Epoch [1 / 3],Step [20200 / 38540], Loss : 4.996774673461914\n",
            "Epoch [1 / 3],Step [20300 / 38540], Loss : 3.7714180946350098\n",
            "Epoch [1 / 3],Step [20400 / 38540], Loss : 6.723458290100098\n",
            "Epoch [1 / 3],Step [20500 / 38540], Loss : 4.548716068267822\n",
            "Epoch [1 / 3],Step [20600 / 38540], Loss : 4.9765305519104\n",
            "Epoch [1 / 3],Step [20700 / 38540], Loss : 4.593490123748779\n",
            "Epoch [1 / 3],Step [20800 / 38540], Loss : 5.657689571380615\n",
            "Epoch [1 / 3],Step [20900 / 38540], Loss : 2.912594795227051\n",
            "Epoch [1 / 3],Step [21000 / 38540], Loss : 4.538307189941406\n",
            "Epoch [1 / 3],Step [21100 / 38540], Loss : 4.130151271820068\n",
            "Epoch [1 / 3],Step [21200 / 38540], Loss : 4.908778190612793\n",
            "Epoch [1 / 3],Step [21300 / 38540], Loss : 5.345363140106201\n",
            "Epoch [1 / 3],Step [21400 / 38540], Loss : 4.6407012939453125\n",
            "Epoch [1 / 3],Step [21500 / 38540], Loss : 5.707973957061768\n",
            "Epoch [1 / 3],Step [21600 / 38540], Loss : 4.121063232421875\n",
            "Epoch [1 / 3],Step [21700 / 38540], Loss : 4.875030040740967\n",
            "Epoch [1 / 3],Step [21800 / 38540], Loss : 6.46999979019165\n",
            "Epoch [1 / 3],Step [21900 / 38540], Loss : 5.509037971496582\n",
            "Epoch [1 / 3],Step [22000 / 38540], Loss : 3.6657392978668213\n",
            "Epoch [1 / 3],Step [22100 / 38540], Loss : 4.211895942687988\n",
            "Epoch [1 / 3],Step [22200 / 38540], Loss : 3.311678171157837\n",
            "Epoch [1 / 3],Step [22300 / 38540], Loss : 5.120030879974365\n",
            "Epoch [1 / 3],Step [22400 / 38540], Loss : 5.504333972930908\n",
            "Epoch [1 / 3],Step [22500 / 38540], Loss : 3.751143217086792\n",
            "Epoch [1 / 3],Step [22600 / 38540], Loss : 4.506348609924316\n",
            "Epoch [1 / 3],Step [22700 / 38540], Loss : 4.324747562408447\n",
            "Epoch [1 / 3],Step [22800 / 38540], Loss : 6.299307823181152\n",
            "Epoch [1 / 3],Step [22900 / 38540], Loss : 3.6235368251800537\n",
            "Epoch [1 / 3],Step [23000 / 38540], Loss : 5.406917572021484\n",
            "Epoch [1 / 3],Step [23100 / 38540], Loss : 2.53937029838562\n",
            "Epoch [1 / 3],Step [23200 / 38540], Loss : 4.7911763191223145\n",
            "Epoch [1 / 3],Step [23300 / 38540], Loss : 4.515671730041504\n",
            "Epoch [1 / 3],Step [23400 / 38540], Loss : 4.500848770141602\n",
            "Epoch [1 / 3],Step [23500 / 38540], Loss : 4.9890875816345215\n",
            "Epoch [1 / 3],Step [23600 / 38540], Loss : 4.876455307006836\n",
            "Epoch [1 / 3],Step [23700 / 38540], Loss : 3.909935474395752\n",
            "Epoch [1 / 3],Step [23800 / 38540], Loss : 5.8325676918029785\n",
            "Epoch [1 / 3],Step [23900 / 38540], Loss : 5.212045192718506\n",
            "Epoch [1 / 3],Step [24000 / 38540], Loss : 4.236974239349365\n",
            "Epoch [1 / 3],Step [24100 / 38540], Loss : 4.642023086547852\n",
            "Epoch [1 / 3],Step [24200 / 38540], Loss : 5.859386920928955\n",
            "Epoch [1 / 3],Step [24300 / 38540], Loss : 3.8972723484039307\n",
            "Epoch [1 / 3],Step [24400 / 38540], Loss : 3.6972365379333496\n",
            "Epoch [1 / 3],Step [24500 / 38540], Loss : 5.046630382537842\n",
            "Epoch [1 / 3],Step [24600 / 38540], Loss : 4.239193916320801\n",
            "Epoch [1 / 3],Step [24700 / 38540], Loss : 4.505035400390625\n",
            "Epoch [1 / 3],Step [24800 / 38540], Loss : 3.773850202560425\n",
            "Epoch [1 / 3],Step [24900 / 38540], Loss : 5.340658664703369\n",
            "Epoch [1 / 3],Step [25000 / 38540], Loss : 5.912675857543945\n",
            "Epoch [1 / 3],Step [25100 / 38540], Loss : 4.978240013122559\n",
            "Epoch [1 / 3],Step [25200 / 38540], Loss : 4.576705455780029\n",
            "Epoch [1 / 3],Step [25300 / 38540], Loss : 5.033031940460205\n",
            "Epoch [1 / 3],Step [25400 / 38540], Loss : 5.3967437744140625\n",
            "Epoch [1 / 3],Step [25500 / 38540], Loss : 4.075115203857422\n",
            "Epoch [1 / 3],Step [25600 / 38540], Loss : 5.193718910217285\n",
            "Epoch [1 / 3],Step [25700 / 38540], Loss : 4.1708197593688965\n",
            "Epoch [1 / 3],Step [25800 / 38540], Loss : 2.3788816928863525\n",
            "Epoch [1 / 3],Step [25900 / 38540], Loss : 2.804767370223999\n",
            "Epoch [1 / 3],Step [26000 / 38540], Loss : 4.305283546447754\n",
            "Epoch [1 / 3],Step [26100 / 38540], Loss : 4.482977390289307\n",
            "Epoch [1 / 3],Step [26200 / 38540], Loss : 3.5387182235717773\n",
            "Epoch [1 / 3],Step [26300 / 38540], Loss : 3.0407533645629883\n",
            "Epoch [1 / 3],Step [26400 / 38540], Loss : 3.9130799770355225\n",
            "Epoch [1 / 3],Step [26500 / 38540], Loss : 3.521588087081909\n",
            "Epoch [1 / 3],Step [26600 / 38540], Loss : 4.331500053405762\n",
            "Epoch [1 / 3],Step [26700 / 38540], Loss : 4.511355876922607\n",
            "Epoch [1 / 3],Step [26800 / 38540], Loss : 5.875286102294922\n",
            "Epoch [1 / 3],Step [26900 / 38540], Loss : 5.893947124481201\n",
            "Epoch [1 / 3],Step [27000 / 38540], Loss : 5.678042411804199\n",
            "Epoch [1 / 3],Step [27100 / 38540], Loss : 5.000117778778076\n",
            "Epoch [1 / 3],Step [27200 / 38540], Loss : 4.8170270919799805\n",
            "Epoch [1 / 3],Step [27300 / 38540], Loss : 3.276465892791748\n",
            "Epoch [1 / 3],Step [27400 / 38540], Loss : 3.0290896892547607\n",
            "Epoch [1 / 3],Step [27500 / 38540], Loss : 5.14621639251709\n",
            "Epoch [1 / 3],Step [27600 / 38540], Loss : 3.587618589401245\n",
            "Epoch [1 / 3],Step [27700 / 38540], Loss : 5.5427680015563965\n",
            "Epoch [1 / 3],Step [27800 / 38540], Loss : 4.164048194885254\n",
            "Epoch [1 / 3],Step [27900 / 38540], Loss : 4.991085529327393\n",
            "Epoch [1 / 3],Step [28000 / 38540], Loss : 5.40401554107666\n",
            "Epoch [1 / 3],Step [28100 / 38540], Loss : 5.012172222137451\n",
            "Epoch [1 / 3],Step [28200 / 38540], Loss : 3.291703701019287\n",
            "Epoch [1 / 3],Step [28300 / 38540], Loss : 3.506227731704712\n",
            "Epoch [1 / 3],Step [28400 / 38540], Loss : 5.272256374359131\n",
            "Epoch [1 / 3],Step [28500 / 38540], Loss : 4.011722087860107\n",
            "Epoch [1 / 3],Step [28600 / 38540], Loss : 4.815854549407959\n",
            "Epoch [1 / 3],Step [28700 / 38540], Loss : 5.0122480392456055\n",
            "Epoch [1 / 3],Step [28800 / 38540], Loss : 4.1779584884643555\n",
            "Epoch [1 / 3],Step [28900 / 38540], Loss : 4.592737197875977\n",
            "Epoch [1 / 3],Step [29000 / 38540], Loss : 3.2981317043304443\n",
            "Epoch [1 / 3],Step [29100 / 38540], Loss : 4.193217754364014\n",
            "Epoch [1 / 3],Step [29200 / 38540], Loss : 2.5818841457366943\n",
            "Epoch [1 / 3],Step [29300 / 38540], Loss : 4.823142051696777\n",
            "Epoch [1 / 3],Step [29400 / 38540], Loss : 5.151973724365234\n",
            "Epoch [1 / 3],Step [29500 / 38540], Loss : 4.508732318878174\n",
            "Epoch [1 / 3],Step [29600 / 38540], Loss : 4.096570014953613\n",
            "Epoch [1 / 3],Step [29700 / 38540], Loss : 5.739782810211182\n",
            "Epoch [1 / 3],Step [29800 / 38540], Loss : 4.815187454223633\n",
            "Epoch [1 / 3],Step [29900 / 38540], Loss : 3.0887157917022705\n",
            "Epoch [1 / 3],Step [30000 / 38540], Loss : 4.103707790374756\n",
            "Epoch [1 / 3],Step [30100 / 38540], Loss : 4.589143753051758\n",
            "Epoch [1 / 3],Step [30200 / 38540], Loss : 3.867051362991333\n",
            "Epoch [1 / 3],Step [30300 / 38540], Loss : 4.281261444091797\n",
            "Epoch [1 / 3],Step [30400 / 38540], Loss : 3.4319682121276855\n",
            "Epoch [1 / 3],Step [30500 / 38540], Loss : 3.7751286029815674\n",
            "Epoch [1 / 3],Step [30600 / 38540], Loss : 6.4100799560546875\n",
            "Epoch [1 / 3],Step [30700 / 38540], Loss : 5.093073844909668\n",
            "Epoch [1 / 3],Step [30800 / 38540], Loss : 3.475764036178589\n",
            "Epoch [1 / 3],Step [30900 / 38540], Loss : 4.058901786804199\n",
            "Epoch [1 / 3],Step [31000 / 38540], Loss : 4.738603591918945\n",
            "Epoch [1 / 3],Step [31100 / 38540], Loss : 4.9084906578063965\n",
            "Epoch [1 / 3],Step [31200 / 38540], Loss : 4.0286359786987305\n",
            "Epoch [1 / 3],Step [31300 / 38540], Loss : 5.148995399475098\n",
            "Epoch [1 / 3],Step [31400 / 38540], Loss : 5.051331996917725\n",
            "Epoch [1 / 3],Step [31500 / 38540], Loss : 4.383249759674072\n",
            "Epoch [1 / 3],Step [31600 / 38540], Loss : 4.507009029388428\n",
            "Epoch [1 / 3],Step [31700 / 38540], Loss : 4.246702671051025\n",
            "Epoch [1 / 3],Step [31800 / 38540], Loss : 4.354519844055176\n",
            "Epoch [1 / 3],Step [31900 / 38540], Loss : 4.664032459259033\n",
            "Epoch [1 / 3],Step [32000 / 38540], Loss : 3.92252254486084\n",
            "Epoch [1 / 3],Step [32100 / 38540], Loss : 4.93453311920166\n",
            "Epoch [1 / 3],Step [32200 / 38540], Loss : 4.7541913986206055\n",
            "Epoch [1 / 3],Step [32300 / 38540], Loss : 4.888195514678955\n",
            "Epoch [1 / 3],Step [32400 / 38540], Loss : 5.319501876831055\n",
            "Epoch [1 / 3],Step [32500 / 38540], Loss : 3.3659138679504395\n",
            "Epoch [1 / 3],Step [32600 / 38540], Loss : 3.1984033584594727\n",
            "Epoch [1 / 3],Step [32700 / 38540], Loss : 3.1957123279571533\n",
            "Epoch [1 / 3],Step [32800 / 38540], Loss : 4.048590183258057\n",
            "Epoch [1 / 3],Step [32900 / 38540], Loss : 5.414206504821777\n",
            "Epoch [1 / 3],Step [33000 / 38540], Loss : 5.144613742828369\n",
            "Epoch [1 / 3],Step [33100 / 38540], Loss : 3.4806807041168213\n",
            "Epoch [1 / 3],Step [33200 / 38540], Loss : 4.301377296447754\n",
            "Epoch [1 / 3],Step [33300 / 38540], Loss : 5.288681983947754\n",
            "Epoch [1 / 3],Step [33400 / 38540], Loss : 5.870185852050781\n",
            "Epoch [1 / 3],Step [33500 / 38540], Loss : 4.182212829589844\n",
            "Epoch [1 / 3],Step [33600 / 38540], Loss : 4.331343173980713\n",
            "Epoch [1 / 3],Step [33700 / 38540], Loss : 5.061329364776611\n",
            "Epoch [1 / 3],Step [33800 / 38540], Loss : 4.286960124969482\n",
            "Epoch [1 / 3],Step [33900 / 38540], Loss : 1.9971044063568115\n",
            "Epoch [1 / 3],Step [34000 / 38540], Loss : 5.654483318328857\n",
            "Epoch [1 / 3],Step [34100 / 38540], Loss : 4.066641330718994\n",
            "Epoch [1 / 3],Step [34200 / 38540], Loss : 3.5034260749816895\n",
            "Epoch [1 / 3],Step [34300 / 38540], Loss : 4.623156547546387\n",
            "Epoch [1 / 3],Step [34400 / 38540], Loss : 1.7092053890228271\n",
            "Epoch [1 / 3],Step [34500 / 38540], Loss : 3.5757980346679688\n",
            "Epoch [1 / 3],Step [34600 / 38540], Loss : 4.14506196975708\n",
            "Epoch [1 / 3],Step [34700 / 38540], Loss : 2.5196800231933594\n",
            "Epoch [1 / 3],Step [34800 / 38540], Loss : 2.9425370693206787\n",
            "Epoch [1 / 3],Step [34900 / 38540], Loss : 3.32199764251709\n",
            "Epoch [1 / 3],Step [35000 / 38540], Loss : 3.9849865436553955\n",
            "Epoch [1 / 3],Step [35100 / 38540], Loss : 3.1956264972686768\n",
            "Epoch [1 / 3],Step [35200 / 38540], Loss : 3.5061757564544678\n",
            "Epoch [1 / 3],Step [35300 / 38540], Loss : 5.107423305511475\n",
            "Epoch [1 / 3],Step [35400 / 38540], Loss : 4.5591654777526855\n",
            "Epoch [1 / 3],Step [35500 / 38540], Loss : 3.508425235748291\n",
            "Epoch [1 / 3],Step [35600 / 38540], Loss : 4.4696455001831055\n",
            "Epoch [1 / 3],Step [35700 / 38540], Loss : 4.116806983947754\n",
            "Epoch [1 / 3],Step [35800 / 38540], Loss : 4.373461723327637\n",
            "Epoch [1 / 3],Step [35900 / 38540], Loss : 2.9531877040863037\n",
            "Epoch [1 / 3],Step [36000 / 38540], Loss : 3.6171483993530273\n",
            "Epoch [1 / 3],Step [36100 / 38540], Loss : 3.584341287612915\n",
            "Epoch [1 / 3],Step [36200 / 38540], Loss : 4.582454204559326\n",
            "Epoch [1 / 3],Step [36300 / 38540], Loss : 4.224520683288574\n",
            "Epoch [1 / 3],Step [36400 / 38540], Loss : 3.3238089084625244\n",
            "Epoch [1 / 3],Step [36500 / 38540], Loss : 5.206423759460449\n",
            "Epoch [1 / 3],Step [36600 / 38540], Loss : 3.3586995601654053\n",
            "Epoch [1 / 3],Step [36700 / 38540], Loss : 4.328357219696045\n",
            "Epoch [1 / 3],Step [36800 / 38540], Loss : 4.643433570861816\n",
            "Epoch [1 / 3],Step [36900 / 38540], Loss : 3.9582979679107666\n",
            "Epoch [1 / 3],Step [37000 / 38540], Loss : 4.000903129577637\n",
            "Epoch [1 / 3],Step [37100 / 38540], Loss : 4.683017730712891\n",
            "Epoch [1 / 3],Step [37200 / 38540], Loss : 3.0097134113311768\n",
            "Epoch [1 / 3],Step [37300 / 38540], Loss : 3.5734541416168213\n",
            "Epoch [1 / 3],Step [37400 / 38540], Loss : 3.942779064178467\n",
            "Epoch [1 / 3],Step [37500 / 38540], Loss : 5.137813091278076\n",
            "Epoch [1 / 3],Step [37600 / 38540], Loss : 2.5208981037139893\n",
            "Epoch [1 / 3],Step [37700 / 38540], Loss : 3.1485209465026855\n",
            "Epoch [1 / 3],Step [37800 / 38540], Loss : 4.90590238571167\n",
            "Epoch [1 / 3],Step [37900 / 38540], Loss : 5.1691765785217285\n",
            "Epoch [1 / 3],Step [38000 / 38540], Loss : 4.625246047973633\n",
            "Epoch [1 / 3],Step [38100 / 38540], Loss : 3.876953363418579\n",
            "Epoch [1 / 3],Step [38200 / 38540], Loss : 3.241706132888794\n",
            "Epoch [1 / 3],Step [38300 / 38540], Loss : 3.147502899169922\n",
            "Epoch [1 / 3],Step [38400 / 38540], Loss : 4.590014934539795\n",
            "Epoch [2 / 3],Step [0 / 38540], Loss : 2.4782376289367676\n",
            "Epoch [2 / 3],Step [100 / 38540], Loss : 2.10252046585083\n",
            "Epoch [2 / 3],Step [200 / 38540], Loss : 2.159149408340454\n",
            "Epoch [2 / 3],Step [300 / 38540], Loss : 3.2400448322296143\n",
            "Epoch [2 / 3],Step [400 / 38540], Loss : 2.233051300048828\n",
            "Epoch [2 / 3],Step [500 / 38540], Loss : 2.2208893299102783\n",
            "Epoch [2 / 3],Step [600 / 38540], Loss : 2.14601469039917\n",
            "Epoch [2 / 3],Step [700 / 38540], Loss : 1.6530600786209106\n",
            "Epoch [2 / 3],Step [800 / 38540], Loss : 2.1910455226898193\n",
            "Epoch [2 / 3],Step [900 / 38540], Loss : 3.0868706703186035\n",
            "Epoch [2 / 3],Step [1000 / 38540], Loss : 3.3039164543151855\n",
            "Epoch [2 / 3],Step [1100 / 38540], Loss : 3.18058705329895\n",
            "Epoch [2 / 3],Step [1200 / 38540], Loss : 2.7933294773101807\n",
            "Epoch [2 / 3],Step [1300 / 38540], Loss : 2.0638327598571777\n",
            "Epoch [2 / 3],Step [1400 / 38540], Loss : 2.251652956008911\n",
            "Epoch [2 / 3],Step [1500 / 38540], Loss : 1.956817865371704\n",
            "Epoch [2 / 3],Step [1600 / 38540], Loss : 2.4040839672088623\n",
            "Epoch [2 / 3],Step [1700 / 38540], Loss : 2.833956003189087\n",
            "Epoch [2 / 3],Step [1800 / 38540], Loss : 2.232513189315796\n",
            "Epoch [2 / 3],Step [1900 / 38540], Loss : 2.313214063644409\n",
            "Epoch [2 / 3],Step [2000 / 38540], Loss : 1.6225507259368896\n",
            "Epoch [2 / 3],Step [2100 / 38540], Loss : 2.2578115463256836\n",
            "Epoch [2 / 3],Step [2200 / 38540], Loss : 1.9140642881393433\n",
            "Epoch [2 / 3],Step [2300 / 38540], Loss : 1.5888514518737793\n",
            "Epoch [2 / 3],Step [2400 / 38540], Loss : 1.8892234563827515\n",
            "Epoch [2 / 3],Step [2500 / 38540], Loss : 1.8633555173873901\n",
            "Epoch [2 / 3],Step [2600 / 38540], Loss : 1.9015494585037231\n",
            "Epoch [2 / 3],Step [2700 / 38540], Loss : 2.0581717491149902\n",
            "Epoch [2 / 3],Step [2800 / 38540], Loss : 1.8312503099441528\n",
            "Epoch [2 / 3],Step [2900 / 38540], Loss : 1.8836475610733032\n",
            "Epoch [2 / 3],Step [3000 / 38540], Loss : 1.6482856273651123\n",
            "Epoch [2 / 3],Step [3100 / 38540], Loss : 1.39564049243927\n",
            "Epoch [2 / 3],Step [3200 / 38540], Loss : 1.8589110374450684\n",
            "Epoch [2 / 3],Step [3300 / 38540], Loss : 1.6552382707595825\n",
            "Epoch [2 / 3],Step [3400 / 38540], Loss : 1.6540004014968872\n",
            "Epoch [2 / 3],Step [3500 / 38540], Loss : 1.9132064580917358\n",
            "Epoch [2 / 3],Step [3600 / 38540], Loss : 1.7917886972427368\n",
            "Epoch [2 / 3],Step [3700 / 38540], Loss : 1.5670067071914673\n",
            "Epoch [2 / 3],Step [3800 / 38540], Loss : 1.643528699874878\n",
            "Epoch [2 / 3],Step [3900 / 38540], Loss : 1.9767489433288574\n",
            "Epoch [2 / 3],Step [4000 / 38540], Loss : 1.6975610256195068\n",
            "Epoch [2 / 3],Step [4100 / 38540], Loss : 1.6637698411941528\n",
            "Epoch [2 / 3],Step [4200 / 38540], Loss : 1.734019160270691\n",
            "Epoch [2 / 3],Step [4300 / 38540], Loss : 1.7580769062042236\n",
            "Epoch [2 / 3],Step [4400 / 38540], Loss : 1.7033010721206665\n",
            "Epoch [2 / 3],Step [4500 / 38540], Loss : 1.666764736175537\n",
            "Epoch [2 / 3],Step [4600 / 38540], Loss : 1.7534794807434082\n",
            "Epoch [2 / 3],Step [4700 / 38540], Loss : 1.6601492166519165\n",
            "Epoch [2 / 3],Step [4800 / 38540], Loss : 1.3611385822296143\n",
            "Epoch [2 / 3],Step [4900 / 38540], Loss : 1.645084023475647\n",
            "Epoch [2 / 3],Step [5000 / 38540], Loss : 2.0597686767578125\n",
            "Epoch [2 / 3],Step [5100 / 38540], Loss : 1.491554856300354\n",
            "Epoch [2 / 3],Step [5200 / 38540], Loss : 1.4330058097839355\n",
            "Epoch [2 / 3],Step [5300 / 38540], Loss : 1.4001858234405518\n",
            "Epoch [2 / 3],Step [5400 / 38540], Loss : 1.6335488557815552\n",
            "Epoch [2 / 3],Step [5500 / 38540], Loss : 1.4337514638900757\n",
            "Epoch [2 / 3],Step [5600 / 38540], Loss : 1.5241302251815796\n",
            "Epoch [2 / 3],Step [5700 / 38540], Loss : 1.5040994882583618\n",
            "Epoch [2 / 3],Step [5800 / 38540], Loss : 1.6667289733886719\n",
            "Epoch [2 / 3],Step [5900 / 38540], Loss : 1.6419415473937988\n",
            "Epoch [2 / 3],Step [6000 / 38540], Loss : 1.505460500717163\n",
            "Epoch [2 / 3],Step [6100 / 38540], Loss : 1.6015820503234863\n",
            "Epoch [2 / 3],Step [6200 / 38540], Loss : 1.4190521240234375\n",
            "Epoch [2 / 3],Step [6300 / 38540], Loss : 1.5644997358322144\n",
            "Epoch [2 / 3],Step [6400 / 38540], Loss : 1.637277603149414\n",
            "Epoch [2 / 3],Step [6500 / 38540], Loss : 1.3592747449874878\n",
            "Epoch [2 / 3],Step [6600 / 38540], Loss : 1.5548845529556274\n",
            "Epoch [2 / 3],Step [6700 / 38540], Loss : 1.6404097080230713\n",
            "Epoch [2 / 3],Step [6800 / 38540], Loss : 1.6551671028137207\n",
            "Epoch [2 / 3],Step [6900 / 38540], Loss : 1.5321182012557983\n",
            "Epoch [2 / 3],Step [7000 / 38540], Loss : 1.5194048881530762\n",
            "Epoch [2 / 3],Step [7100 / 38540], Loss : 1.4980446100234985\n",
            "Epoch [2 / 3],Step [7200 / 38540], Loss : 1.360404133796692\n",
            "Epoch [2 / 3],Step [7300 / 38540], Loss : 1.2642745971679688\n",
            "Epoch [2 / 3],Step [7400 / 38540], Loss : 1.3092750310897827\n",
            "Epoch [2 / 3],Step [7500 / 38540], Loss : 1.6131341457366943\n",
            "Epoch [2 / 3],Step [7600 / 38540], Loss : 1.436455249786377\n",
            "Epoch [2 / 3],Step [7700 / 38540], Loss : 1.4524307250976562\n",
            "Epoch [2 / 3],Step [7800 / 38540], Loss : 1.3935614824295044\n",
            "Epoch [2 / 3],Step [7900 / 38540], Loss : 1.3384766578674316\n",
            "Epoch [2 / 3],Step [8000 / 38540], Loss : 1.5195342302322388\n",
            "Epoch [2 / 3],Step [8100 / 38540], Loss : 1.5607876777648926\n",
            "Epoch [2 / 3],Step [8200 / 38540], Loss : 1.1992897987365723\n",
            "Epoch [2 / 3],Step [8300 / 38540], Loss : 1.340174674987793\n",
            "Epoch [2 / 3],Step [8400 / 38540], Loss : 1.3883781433105469\n",
            "Epoch [2 / 3],Step [8500 / 38540], Loss : 1.364301323890686\n",
            "Epoch [2 / 3],Step [8600 / 38540], Loss : 1.5081133842468262\n",
            "Epoch [2 / 3],Step [8700 / 38540], Loss : 1.4724788665771484\n",
            "Epoch [2 / 3],Step [8800 / 38540], Loss : 1.7021187543869019\n",
            "Epoch [2 / 3],Step [8900 / 38540], Loss : 1.592822790145874\n",
            "Epoch [2 / 3],Step [9000 / 38540], Loss : 1.4299871921539307\n",
            "Epoch [2 / 3],Step [9100 / 38540], Loss : 1.3490198850631714\n",
            "Epoch [2 / 3],Step [9200 / 38540], Loss : 1.1011910438537598\n",
            "Epoch [2 / 3],Step [9300 / 38540], Loss : 1.432772159576416\n",
            "Epoch [2 / 3],Step [9400 / 38540], Loss : 1.6154006719589233\n",
            "Epoch [2 / 3],Step [9500 / 38540], Loss : 1.5037628412246704\n",
            "Epoch [2 / 3],Step [9600 / 38540], Loss : 1.5229673385620117\n",
            "Epoch [2 / 3],Step [9700 / 38540], Loss : 1.3558226823806763\n",
            "Epoch [2 / 3],Step [9800 / 38540], Loss : 1.525319218635559\n",
            "Epoch [2 / 3],Step [9900 / 38540], Loss : 1.2093281745910645\n",
            "Epoch [2 / 3],Step [10000 / 38540], Loss : 1.1465164422988892\n",
            "Epoch [2 / 3],Step [10100 / 38540], Loss : 1.277293086051941\n",
            "Epoch [2 / 3],Step [10200 / 38540], Loss : 1.2867199182510376\n",
            "Epoch [2 / 3],Step [10300 / 38540], Loss : 1.463348388671875\n",
            "Epoch [2 / 3],Step [10400 / 38540], Loss : 1.4829347133636475\n",
            "Epoch [2 / 3],Step [10500 / 38540], Loss : 1.4235159158706665\n",
            "Epoch [2 / 3],Step [10600 / 38540], Loss : 1.4654134511947632\n",
            "Epoch [2 / 3],Step [10700 / 38540], Loss : 1.652510643005371\n",
            "Epoch [2 / 3],Step [10800 / 38540], Loss : 1.2744123935699463\n",
            "Epoch [2 / 3],Step [10900 / 38540], Loss : 1.4172017574310303\n",
            "Epoch [2 / 3],Step [11000 / 38540], Loss : 1.5194958448410034\n",
            "Epoch [2 / 3],Step [11100 / 38540], Loss : 1.316749095916748\n",
            "Epoch [2 / 3],Step [11200 / 38540], Loss : 1.415323257446289\n",
            "Epoch [2 / 3],Step [11300 / 38540], Loss : 1.623287320137024\n",
            "Epoch [2 / 3],Step [11400 / 38540], Loss : 1.2120715379714966\n",
            "Epoch [2 / 3],Step [11500 / 38540], Loss : 1.4730945825576782\n",
            "Epoch [2 / 3],Step [11600 / 38540], Loss : 1.3045868873596191\n",
            "Epoch [2 / 3],Step [11700 / 38540], Loss : 1.4932444095611572\n",
            "Epoch [2 / 3],Step [11800 / 38540], Loss : 1.3188596963882446\n",
            "Epoch [2 / 3],Step [11900 / 38540], Loss : 1.5785467624664307\n",
            "Epoch [2 / 3],Step [12000 / 38540], Loss : 1.3069959878921509\n",
            "Epoch [2 / 3],Step [12100 / 38540], Loss : 1.261789321899414\n",
            "Epoch [2 / 3],Step [12200 / 38540], Loss : 1.430775761604309\n",
            "Epoch [2 / 3],Step [12300 / 38540], Loss : 1.6001451015472412\n",
            "Epoch [2 / 3],Step [12400 / 38540], Loss : 1.2910035848617554\n",
            "Epoch [2 / 3],Step [12500 / 38540], Loss : 1.27444589138031\n",
            "Epoch [2 / 3],Step [12600 / 38540], Loss : 1.2376377582550049\n",
            "Epoch [2 / 3],Step [12700 / 38540], Loss : 1.3237274885177612\n",
            "Epoch [2 / 3],Step [12800 / 38540], Loss : 1.5505716800689697\n",
            "Epoch [2 / 3],Step [12900 / 38540], Loss : 1.318216323852539\n",
            "Epoch [2 / 3],Step [13000 / 38540], Loss : 1.4049432277679443\n",
            "Epoch [2 / 3],Step [13100 / 38540], Loss : 1.290482759475708\n",
            "Epoch [2 / 3],Step [13200 / 38540], Loss : 1.3236802816390991\n",
            "Epoch [2 / 3],Step [13300 / 38540], Loss : 1.651226282119751\n",
            "Epoch [2 / 3],Step [13400 / 38540], Loss : 1.7266356945037842\n",
            "Epoch [2 / 3],Step [13500 / 38540], Loss : 1.3880964517593384\n",
            "Epoch [2 / 3],Step [13600 / 38540], Loss : 1.399093747138977\n",
            "Epoch [2 / 3],Step [13700 / 38540], Loss : 1.4497359991073608\n",
            "Epoch [2 / 3],Step [13800 / 38540], Loss : 1.5016698837280273\n",
            "Epoch [2 / 3],Step [13900 / 38540], Loss : 1.6079457998275757\n",
            "Epoch [2 / 3],Step [14000 / 38540], Loss : 1.1816601753234863\n",
            "Epoch [2 / 3],Step [14100 / 38540], Loss : 1.2297992706298828\n",
            "Epoch [2 / 3],Step [14200 / 38540], Loss : 1.2340031862258911\n",
            "Epoch [2 / 3],Step [14300 / 38540], Loss : 1.275119662284851\n",
            "Epoch [2 / 3],Step [14400 / 38540], Loss : 1.6823155879974365\n",
            "Epoch [2 / 3],Step [14500 / 38540], Loss : 1.3365328311920166\n",
            "Epoch [2 / 3],Step [14600 / 38540], Loss : 1.6028121709823608\n",
            "Epoch [2 / 3],Step [14700 / 38540], Loss : 1.392926573753357\n",
            "Epoch [2 / 3],Step [14800 / 38540], Loss : 1.4848568439483643\n",
            "Epoch [2 / 3],Step [14900 / 38540], Loss : 1.3068374395370483\n",
            "Epoch [2 / 3],Step [15000 / 38540], Loss : 1.2098653316497803\n",
            "Epoch [2 / 3],Step [15100 / 38540], Loss : 1.3085017204284668\n",
            "Epoch [2 / 3],Step [15200 / 38540], Loss : 1.44248628616333\n",
            "Epoch [2 / 3],Step [15300 / 38540], Loss : 1.2650327682495117\n",
            "Epoch [2 / 3],Step [15400 / 38540], Loss : 1.194246768951416\n",
            "Epoch [2 / 3],Step [15500 / 38540], Loss : 1.485579490661621\n",
            "Epoch [2 / 3],Step [15600 / 38540], Loss : 1.6371428966522217\n",
            "Epoch [2 / 3],Step [15700 / 38540], Loss : 1.334562063217163\n",
            "Epoch [2 / 3],Step [15800 / 38540], Loss : 1.1846624612808228\n",
            "Epoch [2 / 3],Step [15900 / 38540], Loss : 1.3086014986038208\n",
            "Epoch [2 / 3],Step [16000 / 38540], Loss : 1.2903913259506226\n",
            "Epoch [2 / 3],Step [16100 / 38540], Loss : 1.2705923318862915\n",
            "Epoch [2 / 3],Step [16200 / 38540], Loss : 1.5210930109024048\n",
            "Epoch [2 / 3],Step [16300 / 38540], Loss : 1.222948431968689\n",
            "Epoch [2 / 3],Step [16400 / 38540], Loss : 1.1676157712936401\n",
            "Epoch [2 / 3],Step [16500 / 38540], Loss : 1.2972934246063232\n",
            "Epoch [2 / 3],Step [16600 / 38540], Loss : 1.3027236461639404\n",
            "Epoch [2 / 3],Step [16700 / 38540], Loss : 1.5523061752319336\n",
            "Epoch [2 / 3],Step [16800 / 38540], Loss : 1.6013463735580444\n",
            "Epoch [2 / 3],Step [16900 / 38540], Loss : 1.0458511114120483\n",
            "Epoch [2 / 3],Step [17000 / 38540], Loss : 1.3144351243972778\n",
            "Epoch [2 / 3],Step [17100 / 38540], Loss : 1.1130925416946411\n",
            "Epoch [2 / 3],Step [17200 / 38540], Loss : 1.249959945678711\n",
            "Epoch [2 / 3],Step [17300 / 38540], Loss : 1.4209825992584229\n",
            "Epoch [2 / 3],Step [17400 / 38540], Loss : 1.41385018825531\n",
            "Epoch [2 / 3],Step [17500 / 38540], Loss : 1.1080659627914429\n",
            "Epoch [2 / 3],Step [17600 / 38540], Loss : 1.2740839719772339\n",
            "Epoch [2 / 3],Step [17700 / 38540], Loss : 1.3475866317749023\n",
            "Epoch [2 / 3],Step [17800 / 38540], Loss : 1.506130337715149\n",
            "Epoch [2 / 3],Step [17900 / 38540], Loss : 1.3072412014007568\n",
            "Epoch [2 / 3],Step [18000 / 38540], Loss : 1.3075039386749268\n",
            "Epoch [2 / 3],Step [18100 / 38540], Loss : 1.2470371723175049\n",
            "Epoch [2 / 3],Step [18200 / 38540], Loss : 1.2797458171844482\n",
            "Epoch [2 / 3],Step [18300 / 38540], Loss : 1.1443172693252563\n",
            "Epoch [2 / 3],Step [18400 / 38540], Loss : 1.1884371042251587\n",
            "Epoch [2 / 3],Step [18500 / 38540], Loss : 1.2715352773666382\n",
            "Epoch [2 / 3],Step [18600 / 38540], Loss : 1.2068055868148804\n",
            "Epoch [2 / 3],Step [18700 / 38540], Loss : 1.3541430234909058\n",
            "Epoch [2 / 3],Step [18800 / 38540], Loss : 1.3134194612503052\n",
            "Epoch [2 / 3],Step [18900 / 38540], Loss : 1.4387699365615845\n",
            "Epoch [2 / 3],Step [19000 / 38540], Loss : 1.3860344886779785\n",
            "Epoch [2 / 3],Step [19100 / 38540], Loss : 1.3312640190124512\n",
            "Epoch [2 / 3],Step [19200 / 38540], Loss : 1.7076243162155151\n",
            "Epoch [2 / 3],Step [19300 / 38540], Loss : 1.1966924667358398\n",
            "Epoch [2 / 3],Step [19400 / 38540], Loss : 1.3264033794403076\n",
            "Epoch [2 / 3],Step [19500 / 38540], Loss : 1.3093904256820679\n",
            "Epoch [2 / 3],Step [19600 / 38540], Loss : 1.3111993074417114\n",
            "Epoch [2 / 3],Step [19700 / 38540], Loss : 1.5454981327056885\n",
            "Epoch [2 / 3],Step [19800 / 38540], Loss : 1.1945966482162476\n",
            "Epoch [2 / 3],Step [19900 / 38540], Loss : 1.635044813156128\n",
            "Epoch [2 / 3],Step [20000 / 38540], Loss : 1.5463355779647827\n",
            "Epoch [2 / 3],Step [20100 / 38540], Loss : 1.646799087524414\n",
            "Epoch [2 / 3],Step [20200 / 38540], Loss : 1.272538185119629\n",
            "Epoch [2 / 3],Step [20300 / 38540], Loss : 1.1103581190109253\n",
            "Epoch [2 / 3],Step [20400 / 38540], Loss : 1.29451322555542\n",
            "Epoch [2 / 3],Step [20500 / 38540], Loss : 1.242416501045227\n",
            "Epoch [2 / 3],Step [20600 / 38540], Loss : 1.0045100450515747\n",
            "Epoch [2 / 3],Step [20700 / 38540], Loss : 1.0660290718078613\n",
            "Epoch [2 / 3],Step [20800 / 38540], Loss : 1.2860181331634521\n",
            "Epoch [2 / 3],Step [20900 / 38540], Loss : 1.3258957862854004\n",
            "Epoch [2 / 3],Step [21000 / 38540], Loss : 1.211129069328308\n",
            "Epoch [2 / 3],Step [21100 / 38540], Loss : 1.2313061952590942\n",
            "Epoch [2 / 3],Step [21200 / 38540], Loss : 1.4862771034240723\n",
            "Epoch [2 / 3],Step [21300 / 38540], Loss : 1.5099059343338013\n",
            "Epoch [2 / 3],Step [21400 / 38540], Loss : 1.4064470529556274\n",
            "Epoch [2 / 3],Step [21500 / 38540], Loss : 1.350332260131836\n",
            "Epoch [2 / 3],Step [21600 / 38540], Loss : 1.3023611307144165\n",
            "Epoch [2 / 3],Step [21700 / 38540], Loss : 1.4653123617172241\n",
            "Epoch [2 / 3],Step [21800 / 38540], Loss : 1.238077998161316\n",
            "Epoch [2 / 3],Step [21900 / 38540], Loss : 1.582092523574829\n",
            "Epoch [2 / 3],Step [22000 / 38540], Loss : 1.2192314863204956\n",
            "Epoch [2 / 3],Step [22100 / 38540], Loss : 1.343001365661621\n",
            "Epoch [2 / 3],Step [22200 / 38540], Loss : 1.192525029182434\n",
            "Epoch [2 / 3],Step [22300 / 38540], Loss : 1.4294387102127075\n",
            "Epoch [2 / 3],Step [22400 / 38540], Loss : 1.5631884336471558\n",
            "Epoch [2 / 3],Step [22500 / 38540], Loss : 1.7916213274002075\n",
            "Epoch [2 / 3],Step [22600 / 38540], Loss : 1.2259957790374756\n",
            "Epoch [2 / 3],Step [22700 / 38540], Loss : 1.1097863912582397\n",
            "Epoch [2 / 3],Step [22800 / 38540], Loss : 1.3567166328430176\n",
            "Epoch [2 / 3],Step [22900 / 38540], Loss : 1.4053425788879395\n",
            "Epoch [2 / 3],Step [23000 / 38540], Loss : 1.763843297958374\n",
            "Epoch [2 / 3],Step [23100 / 38540], Loss : 1.3674991130828857\n",
            "Epoch [2 / 3],Step [23200 / 38540], Loss : 1.2189981937408447\n",
            "Epoch [2 / 3],Step [23300 / 38540], Loss : 1.3129611015319824\n",
            "Epoch [2 / 3],Step [23400 / 38540], Loss : 1.3419528007507324\n",
            "Epoch [2 / 3],Step [23500 / 38540], Loss : 1.2141551971435547\n",
            "Epoch [2 / 3],Step [23600 / 38540], Loss : 1.1637176275253296\n",
            "Epoch [2 / 3],Step [23700 / 38540], Loss : 1.1964263916015625\n",
            "Epoch [2 / 3],Step [23800 / 38540], Loss : 1.3548531532287598\n",
            "Epoch [2 / 3],Step [23900 / 38540], Loss : 1.2821619510650635\n",
            "Epoch [2 / 3],Step [24000 / 38540], Loss : 1.6963034868240356\n",
            "Epoch [2 / 3],Step [24100 / 38540], Loss : 1.2382384538650513\n",
            "Epoch [2 / 3],Step [24200 / 38540], Loss : 1.5231653451919556\n",
            "Epoch [2 / 3],Step [24300 / 38540], Loss : 1.5745747089385986\n",
            "Epoch [2 / 3],Step [24400 / 38540], Loss : 1.1031098365783691\n",
            "Epoch [2 / 3],Step [24500 / 38540], Loss : 1.1150580644607544\n",
            "Epoch [2 / 3],Step [24600 / 38540], Loss : 1.1132217645645142\n",
            "Epoch [2 / 3],Step [24700 / 38540], Loss : 1.180877923965454\n",
            "Epoch [2 / 3],Step [24800 / 38540], Loss : 1.271963357925415\n",
            "Epoch [2 / 3],Step [24900 / 38540], Loss : 1.3175779581069946\n",
            "Epoch [2 / 3],Step [25000 / 38540], Loss : 1.3243876695632935\n",
            "Epoch [2 / 3],Step [25100 / 38540], Loss : 1.5640918016433716\n",
            "Epoch [2 / 3],Step [25200 / 38540], Loss : 1.9646596908569336\n",
            "Epoch [2 / 3],Step [25300 / 38540], Loss : 1.1761373281478882\n",
            "Epoch [2 / 3],Step [25400 / 38540], Loss : 1.4434740543365479\n",
            "Epoch [2 / 3],Step [25500 / 38540], Loss : 1.554268717765808\n",
            "Epoch [2 / 3],Step [25600 / 38540], Loss : 1.3349257707595825\n",
            "Epoch [2 / 3],Step [25700 / 38540], Loss : 1.2581108808517456\n",
            "Epoch [2 / 3],Step [25800 / 38540], Loss : 1.3266332149505615\n",
            "Epoch [2 / 3],Step [25900 / 38540], Loss : 1.5347726345062256\n",
            "Epoch [2 / 3],Step [26000 / 38540], Loss : 1.234405517578125\n",
            "Epoch [2 / 3],Step [26100 / 38540], Loss : 1.4252198934555054\n",
            "Epoch [2 / 3],Step [26200 / 38540], Loss : 1.20270836353302\n",
            "Epoch [2 / 3],Step [26300 / 38540], Loss : 1.3860993385314941\n",
            "Epoch [2 / 3],Step [26400 / 38540], Loss : 1.5035817623138428\n",
            "Epoch [2 / 3],Step [26500 / 38540], Loss : 1.6475259065628052\n",
            "Epoch [2 / 3],Step [26600 / 38540], Loss : 1.113793134689331\n",
            "Epoch [2 / 3],Step [26700 / 38540], Loss : 1.1829379796981812\n",
            "Epoch [2 / 3],Step [26800 / 38540], Loss : 1.2362276315689087\n",
            "Epoch [2 / 3],Step [26900 / 38540], Loss : 1.290200114250183\n",
            "Epoch [2 / 3],Step [27000 / 38540], Loss : 1.2651212215423584\n",
            "Epoch [2 / 3],Step [27100 / 38540], Loss : 1.655752182006836\n",
            "Epoch [2 / 3],Step [27200 / 38540], Loss : 1.0611686706542969\n",
            "Epoch [2 / 3],Step [27300 / 38540], Loss : 1.311585545539856\n",
            "Epoch [2 / 3],Step [27400 / 38540], Loss : 1.090211033821106\n",
            "Epoch [2 / 3],Step [27500 / 38540], Loss : 1.1261482238769531\n",
            "Epoch [2 / 3],Step [27600 / 38540], Loss : 1.19739830493927\n",
            "Epoch [2 / 3],Step [27700 / 38540], Loss : 1.2408150434494019\n",
            "Epoch [2 / 3],Step [27800 / 38540], Loss : 1.145634412765503\n",
            "Epoch [2 / 3],Step [27900 / 38540], Loss : 1.107384204864502\n",
            "Epoch [2 / 3],Step [28000 / 38540], Loss : 1.3497889041900635\n",
            "Epoch [2 / 3],Step [28100 / 38540], Loss : 1.2459990978240967\n",
            "Epoch [2 / 3],Step [28200 / 38540], Loss : 1.405996561050415\n",
            "Epoch [2 / 3],Step [28300 / 38540], Loss : 1.321922779083252\n",
            "Epoch [2 / 3],Step [28400 / 38540], Loss : 1.407546043395996\n",
            "Epoch [2 / 3],Step [28500 / 38540], Loss : 1.3839348554611206\n",
            "Epoch [2 / 3],Step [28600 / 38540], Loss : 1.2343647480010986\n",
            "Epoch [2 / 3],Step [28700 / 38540], Loss : 1.1655189990997314\n",
            "Epoch [2 / 3],Step [28800 / 38540], Loss : 1.235647201538086\n",
            "Epoch [2 / 3],Step [28900 / 38540], Loss : 1.2443877458572388\n",
            "Epoch [2 / 3],Step [29000 / 38540], Loss : 1.2028779983520508\n",
            "Epoch [2 / 3],Step [29100 / 38540], Loss : 1.2519301176071167\n",
            "Epoch [2 / 3],Step [29200 / 38540], Loss : 1.4513996839523315\n",
            "Epoch [2 / 3],Step [29300 / 38540], Loss : 1.4312710762023926\n",
            "Epoch [2 / 3],Step [29400 / 38540], Loss : 1.5339504480361938\n",
            "Epoch [2 / 3],Step [29500 / 38540], Loss : 1.176189661026001\n",
            "Epoch [2 / 3],Step [29600 / 38540], Loss : 1.250118613243103\n",
            "Epoch [2 / 3],Step [29700 / 38540], Loss : 1.1019800901412964\n",
            "Epoch [2 / 3],Step [29800 / 38540], Loss : 1.1340651512145996\n",
            "Epoch [2 / 3],Step [29900 / 38540], Loss : 1.0334378480911255\n",
            "Epoch [2 / 3],Step [30000 / 38540], Loss : 1.2562860250473022\n",
            "Epoch [2 / 3],Step [30100 / 38540], Loss : 1.2570234537124634\n",
            "Epoch [2 / 3],Step [30200 / 38540], Loss : 1.3882938623428345\n",
            "Epoch [2 / 3],Step [30300 / 38540], Loss : 1.593468427658081\n",
            "Epoch [2 / 3],Step [30400 / 38540], Loss : 1.5138274431228638\n",
            "Epoch [2 / 3],Step [30500 / 38540], Loss : 1.1766564846038818\n",
            "Epoch [2 / 3],Step [30600 / 38540], Loss : 1.2561856508255005\n",
            "Epoch [2 / 3],Step [30700 / 38540], Loss : 1.2219480276107788\n",
            "Epoch [2 / 3],Step [30800 / 38540], Loss : 1.4122016429901123\n",
            "Epoch [2 / 3],Step [30900 / 38540], Loss : 1.239378809928894\n",
            "Epoch [2 / 3],Step [31000 / 38540], Loss : 1.171820044517517\n",
            "Epoch [2 / 3],Step [31100 / 38540], Loss : 1.2713382244110107\n",
            "Epoch [2 / 3],Step [31200 / 38540], Loss : 1.2303704023361206\n",
            "Epoch [2 / 3],Step [31300 / 38540], Loss : 1.31531822681427\n",
            "Epoch [2 / 3],Step [31400 / 38540], Loss : 1.2926883697509766\n",
            "Epoch [2 / 3],Step [31500 / 38540], Loss : 1.189150094985962\n",
            "Epoch [2 / 3],Step [31600 / 38540], Loss : 1.3627406358718872\n",
            "Epoch [2 / 3],Step [31700 / 38540], Loss : 1.6776747703552246\n",
            "Epoch [2 / 3],Step [31800 / 38540], Loss : 1.2248272895812988\n",
            "Epoch [2 / 3],Step [31900 / 38540], Loss : 1.2457740306854248\n",
            "Epoch [2 / 3],Step [32000 / 38540], Loss : 1.3477603197097778\n",
            "Epoch [2 / 3],Step [32100 / 38540], Loss : 1.3929623365402222\n",
            "Epoch [2 / 3],Step [32200 / 38540], Loss : 1.7397222518920898\n",
            "Epoch [2 / 3],Step [32300 / 38540], Loss : 1.3527143001556396\n",
            "Epoch [2 / 3],Step [32400 / 38540], Loss : 1.313086986541748\n",
            "Epoch [2 / 3],Step [32500 / 38540], Loss : 1.2333308458328247\n",
            "Epoch [2 / 3],Step [32600 / 38540], Loss : 1.2894243001937866\n",
            "Epoch [2 / 3],Step [32700 / 38540], Loss : 1.6170361042022705\n",
            "Epoch [2 / 3],Step [32800 / 38540], Loss : 1.6212384700775146\n",
            "Epoch [2 / 3],Step [32900 / 38540], Loss : 1.1724283695220947\n",
            "Epoch [2 / 3],Step [33000 / 38540], Loss : 1.2095173597335815\n",
            "Epoch [2 / 3],Step [33100 / 38540], Loss : 1.1775872707366943\n",
            "Epoch [2 / 3],Step [33200 / 38540], Loss : 1.2337864637374878\n",
            "Epoch [2 / 3],Step [33300 / 38540], Loss : 1.4175621271133423\n",
            "Epoch [2 / 3],Step [33400 / 38540], Loss : 1.4573158025741577\n",
            "Epoch [2 / 3],Step [33500 / 38540], Loss : 1.2334332466125488\n",
            "Epoch [2 / 3],Step [33600 / 38540], Loss : 1.4397495985031128\n",
            "Epoch [2 / 3],Step [33700 / 38540], Loss : 1.1764575242996216\n",
            "Epoch [2 / 3],Step [33800 / 38540], Loss : 1.6714386940002441\n",
            "Epoch [2 / 3],Step [33900 / 38540], Loss : 1.0762958526611328\n",
            "Epoch [2 / 3],Step [34000 / 38540], Loss : 1.2509491443634033\n",
            "Epoch [2 / 3],Step [34100 / 38540], Loss : 1.6965481042861938\n",
            "Epoch [2 / 3],Step [34200 / 38540], Loss : 1.213597059249878\n",
            "Epoch [2 / 3],Step [34300 / 38540], Loss : 1.60756254196167\n",
            "Epoch [2 / 3],Step [34400 / 38540], Loss : 1.3430460691452026\n",
            "Epoch [2 / 3],Step [34500 / 38540], Loss : 1.2392377853393555\n",
            "Epoch [2 / 3],Step [34600 / 38540], Loss : 1.5995335578918457\n",
            "Epoch [2 / 3],Step [34700 / 38540], Loss : 1.161961317062378\n",
            "Epoch [2 / 3],Step [34800 / 38540], Loss : 1.31990647315979\n",
            "Epoch [2 / 3],Step [34900 / 38540], Loss : 1.6261087656021118\n",
            "Epoch [2 / 3],Step [35000 / 38540], Loss : 1.0738345384597778\n",
            "Epoch [2 / 3],Step [35100 / 38540], Loss : 1.1994974613189697\n",
            "Epoch [2 / 3],Step [35200 / 38540], Loss : 1.3484766483306885\n",
            "Epoch [2 / 3],Step [35300 / 38540], Loss : 1.6625335216522217\n",
            "Epoch [2 / 3],Step [35400 / 38540], Loss : 1.1607712507247925\n",
            "Epoch [2 / 3],Step [35500 / 38540], Loss : 1.3668785095214844\n",
            "Epoch [2 / 3],Step [35600 / 38540], Loss : 1.5134707689285278\n",
            "Epoch [2 / 3],Step [35700 / 38540], Loss : 1.108975887298584\n",
            "Epoch [2 / 3],Step [35800 / 38540], Loss : 1.247452974319458\n",
            "Epoch [2 / 3],Step [35900 / 38540], Loss : 1.1488564014434814\n",
            "Epoch [2 / 3],Step [36000 / 38540], Loss : 1.228222131729126\n",
            "Epoch [2 / 3],Step [36100 / 38540], Loss : 1.2252719402313232\n",
            "Epoch [2 / 3],Step [36200 / 38540], Loss : 1.278887391090393\n",
            "Epoch [2 / 3],Step [36300 / 38540], Loss : 1.3766584396362305\n",
            "Epoch [2 / 3],Step [36400 / 38540], Loss : 1.4866677522659302\n",
            "Epoch [2 / 3],Step [36500 / 38540], Loss : 1.4142377376556396\n",
            "Epoch [2 / 3],Step [36600 / 38540], Loss : 2.0137994289398193\n",
            "Epoch [2 / 3],Step [36700 / 38540], Loss : 1.4752296209335327\n",
            "Epoch [2 / 3],Step [36800 / 38540], Loss : 1.465761423110962\n",
            "Epoch [2 / 3],Step [36900 / 38540], Loss : 1.4863296747207642\n",
            "Epoch [2 / 3],Step [37000 / 38540], Loss : 1.047102689743042\n",
            "Epoch [2 / 3],Step [37100 / 38540], Loss : 1.0911238193511963\n",
            "Epoch [2 / 3],Step [37200 / 38540], Loss : 1.065561294555664\n",
            "Epoch [2 / 3],Step [37300 / 38540], Loss : 1.1491338014602661\n",
            "Epoch [2 / 3],Step [37400 / 38540], Loss : 1.2351267337799072\n",
            "Epoch [2 / 3],Step [37500 / 38540], Loss : 1.561326265335083\n",
            "Epoch [2 / 3],Step [37600 / 38540], Loss : 1.2154736518859863\n",
            "Epoch [2 / 3],Step [37700 / 38540], Loss : 1.6206185817718506\n",
            "Epoch [2 / 3],Step [37800 / 38540], Loss : 1.1281522512435913\n",
            "Epoch [2 / 3],Step [37900 / 38540], Loss : 1.0358937978744507\n",
            "Epoch [2 / 3],Step [38000 / 38540], Loss : 1.2093230485916138\n",
            "Epoch [2 / 3],Step [38100 / 38540], Loss : 0.9960824847221375\n",
            "Epoch [2 / 3],Step [38200 / 38540], Loss : 0.8826305866241455\n",
            "Epoch [2 / 3],Step [38300 / 38540], Loss : 1.09058678150177\n",
            "Epoch [2 / 3],Step [38400 / 38540], Loss : 1.0863937139511108\n",
            "Epoch [3 / 3],Step [0 / 38540], Loss : 1.3585865497589111\n",
            "Epoch [3 / 3],Step [100 / 38540], Loss : 1.2508496046066284\n",
            "Epoch [3 / 3],Step [200 / 38540], Loss : 1.3447339534759521\n",
            "Epoch [3 / 3],Step [300 / 38540], Loss : 1.4978362321853638\n",
            "Epoch [3 / 3],Step [400 / 38540], Loss : 1.31856107711792\n",
            "Epoch [3 / 3],Step [500 / 38540], Loss : 1.2514183521270752\n",
            "Epoch [3 / 3],Step [600 / 38540], Loss : 1.1881130933761597\n",
            "Epoch [3 / 3],Step [700 / 38540], Loss : 1.1241455078125\n",
            "Epoch [3 / 3],Step [800 / 38540], Loss : 1.4020975828170776\n",
            "Epoch [3 / 3],Step [900 / 38540], Loss : 1.5757851600646973\n",
            "Epoch [3 / 3],Step [1000 / 38540], Loss : 1.865665078163147\n",
            "Epoch [3 / 3],Step [1100 / 38540], Loss : 1.6589268445968628\n",
            "Epoch [3 / 3],Step [1200 / 38540], Loss : 1.6149245500564575\n",
            "Epoch [3 / 3],Step [1300 / 38540], Loss : 1.5007505416870117\n",
            "Epoch [3 / 3],Step [1400 / 38540], Loss : 1.4317752122879028\n",
            "Epoch [3 / 3],Step [1500 / 38540], Loss : 1.1740728616714478\n",
            "Epoch [3 / 3],Step [1600 / 38540], Loss : 1.3756104707717896\n",
            "Epoch [3 / 3],Step [1700 / 38540], Loss : 1.7329858541488647\n",
            "Epoch [3 / 3],Step [1800 / 38540], Loss : 1.4636034965515137\n",
            "Epoch [3 / 3],Step [1900 / 38540], Loss : 1.4376195669174194\n",
            "Epoch [3 / 3],Step [2000 / 38540], Loss : 1.176851511001587\n",
            "Epoch [3 / 3],Step [2100 / 38540], Loss : 1.4979517459869385\n",
            "Epoch [3 / 3],Step [2200 / 38540], Loss : 1.4524842500686646\n",
            "Epoch [3 / 3],Step [2300 / 38540], Loss : 1.3495360612869263\n",
            "Epoch [3 / 3],Step [2400 / 38540], Loss : 1.2915116548538208\n",
            "Epoch [3 / 3],Step [2500 / 38540], Loss : 1.3608721494674683\n",
            "Epoch [3 / 3],Step [2600 / 38540], Loss : 1.3207778930664062\n",
            "Epoch [3 / 3],Step [2700 / 38540], Loss : 1.5707298517227173\n",
            "Epoch [3 / 3],Step [2800 / 38540], Loss : 1.2207058668136597\n",
            "Epoch [3 / 3],Step [2900 / 38540], Loss : 1.5520620346069336\n",
            "Epoch [3 / 3],Step [3000 / 38540], Loss : 1.2012279033660889\n",
            "Epoch [3 / 3],Step [3100 / 38540], Loss : 1.1763147115707397\n",
            "Epoch [3 / 3],Step [3200 / 38540], Loss : 1.4497201442718506\n",
            "Epoch [3 / 3],Step [3300 / 38540], Loss : 1.2155191898345947\n",
            "Epoch [3 / 3],Step [3400 / 38540], Loss : 1.2923682928085327\n",
            "Epoch [3 / 3],Step [3500 / 38540], Loss : 1.2342777252197266\n",
            "Epoch [3 / 3],Step [3600 / 38540], Loss : 1.398476481437683\n",
            "Epoch [3 / 3],Step [3700 / 38540], Loss : 1.2246431112289429\n",
            "Epoch [3 / 3],Step [3800 / 38540], Loss : 1.2722219228744507\n",
            "Epoch [3 / 3],Step [3900 / 38540], Loss : 1.3539166450500488\n",
            "Epoch [3 / 3],Step [4000 / 38540], Loss : 1.199104905128479\n",
            "Epoch [3 / 3],Step [4100 / 38540], Loss : 1.3253165483474731\n",
            "Epoch [3 / 3],Step [4200 / 38540], Loss : 1.2336417436599731\n",
            "Epoch [3 / 3],Step [4300 / 38540], Loss : 1.320723056793213\n",
            "Epoch [3 / 3],Step [4400 / 38540], Loss : 1.4044088125228882\n",
            "Epoch [3 / 3],Step [4500 / 38540], Loss : 1.2887932062149048\n",
            "Epoch [3 / 3],Step [4600 / 38540], Loss : 1.3312162160873413\n",
            "Epoch [3 / 3],Step [4700 / 38540], Loss : 1.291725993156433\n",
            "Epoch [3 / 3],Step [4800 / 38540], Loss : 1.1472035646438599\n",
            "Epoch [3 / 3],Step [4900 / 38540], Loss : 1.2534219026565552\n",
            "Epoch [3 / 3],Step [5000 / 38540], Loss : 1.4930024147033691\n",
            "Epoch [3 / 3],Step [5100 / 38540], Loss : 1.1787545680999756\n",
            "Epoch [3 / 3],Step [5200 / 38540], Loss : 1.2305190563201904\n",
            "Epoch [3 / 3],Step [5300 / 38540], Loss : 1.3439900875091553\n",
            "Epoch [3 / 3],Step [5400 / 38540], Loss : 1.1933635473251343\n",
            "Epoch [3 / 3],Step [5500 / 38540], Loss : 1.2359340190887451\n",
            "Epoch [3 / 3],Step [5600 / 38540], Loss : 1.1204159259796143\n",
            "Epoch [3 / 3],Step [5700 / 38540], Loss : 1.0293068885803223\n",
            "Epoch [3 / 3],Step [5800 / 38540], Loss : 1.2639141082763672\n",
            "Epoch [3 / 3],Step [5900 / 38540], Loss : 1.2872545719146729\n",
            "Epoch [3 / 3],Step [6000 / 38540], Loss : 1.377027988433838\n",
            "Epoch [3 / 3],Step [6100 / 38540], Loss : 1.1977965831756592\n",
            "Epoch [3 / 3],Step [6200 / 38540], Loss : 1.2102644443511963\n",
            "Epoch [3 / 3],Step [6300 / 38540], Loss : 1.2051633596420288\n",
            "Epoch [3 / 3],Step [6400 / 38540], Loss : 1.163003921508789\n",
            "Epoch [3 / 3],Step [6500 / 38540], Loss : 1.109753966331482\n",
            "Epoch [3 / 3],Step [6600 / 38540], Loss : 1.270915150642395\n",
            "Epoch [3 / 3],Step [6700 / 38540], Loss : 1.2715282440185547\n",
            "Epoch [3 / 3],Step [6800 / 38540], Loss : 1.1764296293258667\n",
            "Epoch [3 / 3],Step [6900 / 38540], Loss : 1.1952415704727173\n",
            "Epoch [3 / 3],Step [7000 / 38540], Loss : 1.127120018005371\n",
            "Epoch [3 / 3],Step [7100 / 38540], Loss : 1.238179326057434\n",
            "Epoch [3 / 3],Step [7200 / 38540], Loss : 1.2450969219207764\n",
            "Epoch [3 / 3],Step [7300 / 38540], Loss : 1.0541540384292603\n",
            "Epoch [3 / 3],Step [7400 / 38540], Loss : 1.1739768981933594\n",
            "Epoch [3 / 3],Step [7500 / 38540], Loss : 1.4684442281723022\n",
            "Epoch [3 / 3],Step [7600 / 38540], Loss : 1.1664265394210815\n",
            "Epoch [3 / 3],Step [7700 / 38540], Loss : 1.2653751373291016\n",
            "Epoch [3 / 3],Step [7800 / 38540], Loss : 1.0821900367736816\n",
            "Epoch [3 / 3],Step [7900 / 38540], Loss : 1.0235358476638794\n",
            "Epoch [3 / 3],Step [8000 / 38540], Loss : 1.0872186422348022\n",
            "Epoch [3 / 3],Step [8100 / 38540], Loss : 1.2451646327972412\n",
            "Epoch [3 / 3],Step [8200 / 38540], Loss : 1.1205551624298096\n",
            "Epoch [3 / 3],Step [8300 / 38540], Loss : 1.1605764627456665\n",
            "Epoch [3 / 3],Step [8400 / 38540], Loss : 1.1778446435928345\n",
            "Epoch [3 / 3],Step [8500 / 38540], Loss : 1.0533827543258667\n",
            "Epoch [3 / 3],Step [8600 / 38540], Loss : 1.0517421960830688\n",
            "Epoch [3 / 3],Step [8700 / 38540], Loss : 1.0726712942123413\n",
            "Epoch [3 / 3],Step [8800 / 38540], Loss : 1.2050739526748657\n",
            "Epoch [3 / 3],Step [8900 / 38540], Loss : 1.250243902206421\n",
            "Epoch [3 / 3],Step [9000 / 38540], Loss : 1.2782267332077026\n",
            "Epoch [3 / 3],Step [9100 / 38540], Loss : 1.0703492164611816\n",
            "Epoch [3 / 3],Step [9200 / 38540], Loss : 0.9261816143989563\n",
            "Epoch [3 / 3],Step [9300 / 38540], Loss : 1.1528693437576294\n",
            "Epoch [3 / 3],Step [9400 / 38540], Loss : 1.2464473247528076\n",
            "Epoch [3 / 3],Step [9500 / 38540], Loss : 1.115767240524292\n",
            "Epoch [3 / 3],Step [9600 / 38540], Loss : 1.1188788414001465\n",
            "Epoch [3 / 3],Step [9700 / 38540], Loss : 0.9105614423751831\n",
            "Epoch [3 / 3],Step [9800 / 38540], Loss : 1.244655728340149\n",
            "Epoch [3 / 3],Step [9900 / 38540], Loss : 1.1002978086471558\n",
            "Epoch [3 / 3],Step [10000 / 38540], Loss : 1.175903558731079\n",
            "Epoch [3 / 3],Step [10100 / 38540], Loss : 1.2770142555236816\n",
            "Epoch [3 / 3],Step [10200 / 38540], Loss : 0.9771192669868469\n",
            "Epoch [3 / 3],Step [10300 / 38540], Loss : 1.1020264625549316\n",
            "Epoch [3 / 3],Step [10400 / 38540], Loss : 1.2834066152572632\n",
            "Epoch [3 / 3],Step [10500 / 38540], Loss : 1.1643863916397095\n",
            "Epoch [3 / 3],Step [10600 / 38540], Loss : 1.1724668741226196\n",
            "Epoch [3 / 3],Step [10700 / 38540], Loss : 1.2051259279251099\n",
            "Epoch [3 / 3],Step [10800 / 38540], Loss : 1.1102910041809082\n",
            "Epoch [3 / 3],Step [10900 / 38540], Loss : 1.1782699823379517\n",
            "Epoch [3 / 3],Step [11000 / 38540], Loss : 1.1015254259109497\n",
            "Epoch [3 / 3],Step [11100 / 38540], Loss : 1.1006107330322266\n",
            "Epoch [3 / 3],Step [11200 / 38540], Loss : 1.0477114915847778\n",
            "Epoch [3 / 3],Step [11300 / 38540], Loss : 1.0787949562072754\n",
            "Epoch [3 / 3],Step [11400 / 38540], Loss : 0.9528023600578308\n",
            "Epoch [3 / 3],Step [11500 / 38540], Loss : 1.2123490571975708\n",
            "Epoch [3 / 3],Step [11600 / 38540], Loss : 1.2290613651275635\n",
            "Epoch [3 / 3],Step [11700 / 38540], Loss : 0.9984968304634094\n",
            "Epoch [3 / 3],Step [11800 / 38540], Loss : 1.0740090608596802\n",
            "Epoch [3 / 3],Step [11900 / 38540], Loss : 1.3288811445236206\n",
            "Epoch [3 / 3],Step [12000 / 38540], Loss : 1.1149818897247314\n",
            "Epoch [3 / 3],Step [12100 / 38540], Loss : 1.0382112264633179\n",
            "Epoch [3 / 3],Step [12200 / 38540], Loss : 1.1309120655059814\n",
            "Epoch [3 / 3],Step [12300 / 38540], Loss : 1.035288691520691\n",
            "Epoch [3 / 3],Step [12400 / 38540], Loss : 1.2149741649627686\n",
            "Epoch [3 / 3],Step [12500 / 38540], Loss : 1.0923511981964111\n",
            "Epoch [3 / 3],Step [12600 / 38540], Loss : 1.2367455959320068\n",
            "Epoch [3 / 3],Step [12700 / 38540], Loss : 1.1142864227294922\n",
            "Epoch [3 / 3],Step [12800 / 38540], Loss : 1.1787279844284058\n",
            "Epoch [3 / 3],Step [12900 / 38540], Loss : 1.000966191291809\n",
            "Epoch [3 / 3],Step [13000 / 38540], Loss : 1.061309576034546\n",
            "Epoch [3 / 3],Step [13100 / 38540], Loss : 1.0508885383605957\n",
            "Epoch [3 / 3],Step [13200 / 38540], Loss : 1.0152168273925781\n",
            "Epoch [3 / 3],Step [13300 / 38540], Loss : 1.0866105556488037\n",
            "Epoch [3 / 3],Step [13400 / 38540], Loss : 1.3436764478683472\n",
            "Epoch [3 / 3],Step [13500 / 38540], Loss : 1.1400667428970337\n",
            "Epoch [3 / 3],Step [13600 / 38540], Loss : 1.1060413122177124\n",
            "Epoch [3 / 3],Step [13700 / 38540], Loss : 1.0991381406784058\n",
            "Epoch [3 / 3],Step [13800 / 38540], Loss : 1.173526406288147\n",
            "Epoch [3 / 3],Step [13900 / 38540], Loss : 1.020378589630127\n",
            "Epoch [3 / 3],Step [14000 / 38540], Loss : 1.1202547550201416\n",
            "Epoch [3 / 3],Step [14100 / 38540], Loss : 1.1770633459091187\n",
            "Epoch [3 / 3],Step [14200 / 38540], Loss : 1.0003654956817627\n",
            "Epoch [3 / 3],Step [14300 / 38540], Loss : 1.0555294752120972\n",
            "Epoch [3 / 3],Step [14400 / 38540], Loss : 1.080669641494751\n",
            "Epoch [3 / 3],Step [14500 / 38540], Loss : 1.141150951385498\n",
            "Epoch [3 / 3],Step [14600 / 38540], Loss : 0.998990535736084\n",
            "Epoch [3 / 3],Step [14700 / 38540], Loss : 0.982663094997406\n",
            "Epoch [3 / 3],Step [14800 / 38540], Loss : 1.106813907623291\n",
            "Epoch [3 / 3],Step [14900 / 38540], Loss : 1.0913209915161133\n",
            "Epoch [3 / 3],Step [15000 / 38540], Loss : 1.2127891778945923\n",
            "Epoch [3 / 3],Step [15100 / 38540], Loss : 1.0606385469436646\n",
            "Epoch [3 / 3],Step [15200 / 38540], Loss : 0.9798787236213684\n",
            "Epoch [3 / 3],Step [15300 / 38540], Loss : 1.1315443515777588\n",
            "Epoch [3 / 3],Step [15400 / 38540], Loss : 1.0118870735168457\n",
            "Epoch [3 / 3],Step [15500 / 38540], Loss : 1.1547693014144897\n",
            "Epoch [3 / 3],Step [15600 / 38540], Loss : 1.0082378387451172\n",
            "Epoch [3 / 3],Step [15700 / 38540], Loss : 1.1848443746566772\n",
            "Epoch [3 / 3],Step [15800 / 38540], Loss : 1.1619549989700317\n",
            "Epoch [3 / 3],Step [15900 / 38540], Loss : 1.176209807395935\n",
            "Epoch [3 / 3],Step [16000 / 38540], Loss : 1.0340532064437866\n",
            "Epoch [3 / 3],Step [16100 / 38540], Loss : 0.9814751744270325\n",
            "Epoch [3 / 3],Step [16200 / 38540], Loss : 1.2619210481643677\n",
            "Epoch [3 / 3],Step [16300 / 38540], Loss : 1.0430582761764526\n",
            "Epoch [3 / 3],Step [16400 / 38540], Loss : 1.0123233795166016\n",
            "Epoch [3 / 3],Step [16500 / 38540], Loss : 1.1976200342178345\n",
            "Epoch [3 / 3],Step [16600 / 38540], Loss : 1.1635406017303467\n",
            "Epoch [3 / 3],Step [16700 / 38540], Loss : 1.169306993484497\n",
            "Epoch [3 / 3],Step [16800 / 38540], Loss : 1.1231783628463745\n",
            "Epoch [3 / 3],Step [16900 / 38540], Loss : 1.0546019077301025\n",
            "Epoch [3 / 3],Step [17000 / 38540], Loss : 1.2000805139541626\n",
            "Epoch [3 / 3],Step [17100 / 38540], Loss : 1.0560827255249023\n",
            "Epoch [3 / 3],Step [17200 / 38540], Loss : 1.0656119585037231\n",
            "Epoch [3 / 3],Step [17300 / 38540], Loss : 1.026962399482727\n",
            "Epoch [3 / 3],Step [17400 / 38540], Loss : 1.1309497356414795\n",
            "Epoch [3 / 3],Step [17500 / 38540], Loss : 1.1559371948242188\n",
            "Epoch [3 / 3],Step [17600 / 38540], Loss : 1.114756464958191\n",
            "Epoch [3 / 3],Step [17700 / 38540], Loss : 1.1152704954147339\n",
            "Epoch [3 / 3],Step [17800 / 38540], Loss : 1.191007375717163\n",
            "Epoch [3 / 3],Step [17900 / 38540], Loss : 1.0873284339904785\n",
            "Epoch [3 / 3],Step [18000 / 38540], Loss : 1.1817662715911865\n",
            "Epoch [3 / 3],Step [18100 / 38540], Loss : 1.0001438856124878\n",
            "Epoch [3 / 3],Step [18200 / 38540], Loss : 1.0143229961395264\n",
            "Epoch [3 / 3],Step [18300 / 38540], Loss : 1.093974232673645\n",
            "Epoch [3 / 3],Step [18400 / 38540], Loss : 1.049202799797058\n",
            "Epoch [3 / 3],Step [18500 / 38540], Loss : 1.202168345451355\n",
            "Epoch [3 / 3],Step [18600 / 38540], Loss : 0.988857626914978\n",
            "Epoch [3 / 3],Step [18700 / 38540], Loss : 1.0329055786132812\n",
            "Epoch [3 / 3],Step [18800 / 38540], Loss : 1.0835216045379639\n",
            "Epoch [3 / 3],Step [18900 / 38540], Loss : 1.0315531492233276\n",
            "Epoch [3 / 3],Step [19000 / 38540], Loss : 1.0416556596755981\n",
            "Epoch [3 / 3],Step [19100 / 38540], Loss : 0.9237112402915955\n",
            "Epoch [3 / 3],Step [19200 / 38540], Loss : 1.0542351007461548\n",
            "Epoch [3 / 3],Step [19300 / 38540], Loss : 1.3524852991104126\n",
            "Epoch [3 / 3],Step [19400 / 38540], Loss : 1.0751415491104126\n",
            "Epoch [3 / 3],Step [19500 / 38540], Loss : 1.124468207359314\n",
            "Epoch [3 / 3],Step [19600 / 38540], Loss : 0.9983846545219421\n",
            "Epoch [3 / 3],Step [19700 / 38540], Loss : 0.9799755811691284\n",
            "Epoch [3 / 3],Step [19800 / 38540], Loss : 1.0063461065292358\n",
            "Epoch [3 / 3],Step [19900 / 38540], Loss : 1.1211780309677124\n",
            "Epoch [3 / 3],Step [20000 / 38540], Loss : 1.0711320638656616\n",
            "Epoch [3 / 3],Step [20100 / 38540], Loss : 1.0466077327728271\n",
            "Epoch [3 / 3],Step [20200 / 38540], Loss : 1.2718521356582642\n",
            "Epoch [3 / 3],Step [20300 / 38540], Loss : 1.0669184923171997\n",
            "Epoch [3 / 3],Step [20400 / 38540], Loss : 1.0363168716430664\n",
            "Epoch [3 / 3],Step [20500 / 38540], Loss : 1.1354353427886963\n",
            "Epoch [3 / 3],Step [20600 / 38540], Loss : 1.048030972480774\n",
            "Epoch [3 / 3],Step [20700 / 38540], Loss : 1.0162285566329956\n",
            "Epoch [3 / 3],Step [20800 / 38540], Loss : 1.098369836807251\n",
            "Epoch [3 / 3],Step [20900 / 38540], Loss : 1.0358672142028809\n",
            "Epoch [3 / 3],Step [21000 / 38540], Loss : 1.0194616317749023\n",
            "Epoch [3 / 3],Step [21100 / 38540], Loss : 1.0359580516815186\n",
            "Epoch [3 / 3],Step [21200 / 38540], Loss : 1.14164400100708\n",
            "Epoch [3 / 3],Step [21300 / 38540], Loss : 1.050441861152649\n",
            "Epoch [3 / 3],Step [21400 / 38540], Loss : 1.0646687746047974\n",
            "Epoch [3 / 3],Step [21500 / 38540], Loss : 1.113547921180725\n",
            "Epoch [3 / 3],Step [21600 / 38540], Loss : 1.0438019037246704\n",
            "Epoch [3 / 3],Step [21700 / 38540], Loss : 1.0276381969451904\n",
            "Epoch [3 / 3],Step [21800 / 38540], Loss : 1.1155024766921997\n",
            "Epoch [3 / 3],Step [21900 / 38540], Loss : 1.0658272504806519\n",
            "Epoch [3 / 3],Step [22000 / 38540], Loss : 0.9763368964195251\n",
            "Epoch [3 / 3],Step [22100 / 38540], Loss : 0.9803826212882996\n",
            "Epoch [3 / 3],Step [22200 / 38540], Loss : 0.9748122096061707\n",
            "Epoch [3 / 3],Step [22300 / 38540], Loss : 1.0042757987976074\n",
            "Epoch [3 / 3],Step [22400 / 38540], Loss : 1.2544710636138916\n",
            "Epoch [3 / 3],Step [22500 / 38540], Loss : 1.0643771886825562\n",
            "Epoch [3 / 3],Step [22600 / 38540], Loss : 1.025395154953003\n",
            "Epoch [3 / 3],Step [22700 / 38540], Loss : 1.0832535028457642\n",
            "Epoch [3 / 3],Step [22800 / 38540], Loss : 1.1061378717422485\n",
            "Epoch [3 / 3],Step [22900 / 38540], Loss : 0.9986976385116577\n",
            "Epoch [3 / 3],Step [23000 / 38540], Loss : 1.1524311304092407\n",
            "Epoch [3 / 3],Step [23100 / 38540], Loss : 1.083609938621521\n",
            "Epoch [3 / 3],Step [23200 / 38540], Loss : 1.0656946897506714\n",
            "Epoch [3 / 3],Step [23300 / 38540], Loss : 1.0245112180709839\n",
            "Epoch [3 / 3],Step [23400 / 38540], Loss : 1.0752900838851929\n",
            "Epoch [3 / 3],Step [23500 / 38540], Loss : 1.1618174314498901\n",
            "Epoch [3 / 3],Step [23600 / 38540], Loss : 0.9429754614830017\n",
            "Epoch [3 / 3],Step [23700 / 38540], Loss : 1.1836342811584473\n",
            "Epoch [3 / 3],Step [23800 / 38540], Loss : 1.114166021347046\n",
            "Epoch [3 / 3],Step [23900 / 38540], Loss : 0.9944305419921875\n",
            "Epoch [3 / 3],Step [24000 / 38540], Loss : 1.0567659139633179\n",
            "Epoch [3 / 3],Step [24100 / 38540], Loss : 1.0421431064605713\n",
            "Epoch [3 / 3],Step [24200 / 38540], Loss : 1.0926151275634766\n",
            "Epoch [3 / 3],Step [24300 / 38540], Loss : 0.9625817537307739\n",
            "Epoch [3 / 3],Step [24400 / 38540], Loss : 1.055318832397461\n",
            "Epoch [3 / 3],Step [24500 / 38540], Loss : 1.0465651750564575\n",
            "Epoch [3 / 3],Step [24600 / 38540], Loss : 1.111953616142273\n",
            "Epoch [3 / 3],Step [24700 / 38540], Loss : 1.0504581928253174\n",
            "Epoch [3 / 3],Step [24800 / 38540], Loss : 1.1407763957977295\n",
            "Epoch [3 / 3],Step [24900 / 38540], Loss : 1.0390794277191162\n",
            "Epoch [3 / 3],Step [25000 / 38540], Loss : 1.0198067426681519\n",
            "Epoch [3 / 3],Step [25100 / 38540], Loss : 1.1203961372375488\n",
            "Epoch [3 / 3],Step [25200 / 38540], Loss : 0.9720360636711121\n",
            "Epoch [3 / 3],Step [25300 / 38540], Loss : 1.038345217704773\n",
            "Epoch [3 / 3],Step [25400 / 38540], Loss : 0.9533002972602844\n",
            "Epoch [3 / 3],Step [25500 / 38540], Loss : 1.1114610433578491\n",
            "Epoch [3 / 3],Step [25600 / 38540], Loss : 1.024887204170227\n",
            "Epoch [3 / 3],Step [25700 / 38540], Loss : 0.9091268181800842\n",
            "Epoch [3 / 3],Step [25800 / 38540], Loss : 1.029085397720337\n",
            "Epoch [3 / 3],Step [25900 / 38540], Loss : 1.076854944229126\n",
            "Epoch [3 / 3],Step [26000 / 38540], Loss : 1.0289039611816406\n",
            "Epoch [3 / 3],Step [26100 / 38540], Loss : 0.8378683924674988\n",
            "Epoch [3 / 3],Step [26200 / 38540], Loss : 1.1288856267929077\n",
            "Epoch [3 / 3],Step [26300 / 38540], Loss : 1.0465832948684692\n",
            "Epoch [3 / 3],Step [26400 / 38540], Loss : 0.9760897755622864\n",
            "Epoch [3 / 3],Step [26500 / 38540], Loss : 1.1947590112686157\n",
            "Epoch [3 / 3],Step [26600 / 38540], Loss : 1.1336116790771484\n",
            "Epoch [3 / 3],Step [26700 / 38540], Loss : 0.9971384406089783\n",
            "Epoch [3 / 3],Step [26800 / 38540], Loss : 1.0902042388916016\n",
            "Epoch [3 / 3],Step [26900 / 38540], Loss : 1.0820400714874268\n",
            "Epoch [3 / 3],Step [27000 / 38540], Loss : 1.1530635356903076\n",
            "Epoch [3 / 3],Step [27100 / 38540], Loss : 0.9810807108879089\n",
            "Epoch [3 / 3],Step [27200 / 38540], Loss : 0.9379428029060364\n",
            "Epoch [3 / 3],Step [27300 / 38540], Loss : 1.0475367307662964\n",
            "Epoch [3 / 3],Step [27400 / 38540], Loss : 0.9762017726898193\n",
            "Epoch [3 / 3],Step [27500 / 38540], Loss : 0.9791789650917053\n",
            "Epoch [3 / 3],Step [27600 / 38540], Loss : 1.1637216806411743\n",
            "Epoch [3 / 3],Step [27700 / 38540], Loss : 0.9819344282150269\n",
            "Epoch [3 / 3],Step [27800 / 38540], Loss : 0.9849196672439575\n",
            "Epoch [3 / 3],Step [27900 / 38540], Loss : 1.1177610158920288\n",
            "Epoch [3 / 3],Step [28000 / 38540], Loss : 1.0103529691696167\n",
            "Epoch [3 / 3],Step [28100 / 38540], Loss : 1.0068714618682861\n",
            "Epoch [3 / 3],Step [28200 / 38540], Loss : 0.9590787291526794\n",
            "Epoch [3 / 3],Step [28300 / 38540], Loss : 0.9818736910820007\n",
            "Epoch [3 / 3],Step [28400 / 38540], Loss : 1.0410982370376587\n",
            "Epoch [3 / 3],Step [28500 / 38540], Loss : 1.0094735622406006\n",
            "Epoch [3 / 3],Step [28600 / 38540], Loss : 1.05991792678833\n",
            "Epoch [3 / 3],Step [28700 / 38540], Loss : 0.9901811480522156\n",
            "Epoch [3 / 3],Step [28800 / 38540], Loss : 0.8991416096687317\n",
            "Epoch [3 / 3],Step [28900 / 38540], Loss : 0.9686227440834045\n",
            "Epoch [3 / 3],Step [29000 / 38540], Loss : 0.9341664910316467\n",
            "Epoch [3 / 3],Step [29100 / 38540], Loss : 1.1125543117523193\n",
            "Epoch [3 / 3],Step [29200 / 38540], Loss : 1.0697554349899292\n",
            "Epoch [3 / 3],Step [29300 / 38540], Loss : 0.9970651268959045\n",
            "Epoch [3 / 3],Step [29400 / 38540], Loss : 1.148236632347107\n",
            "Epoch [3 / 3],Step [29500 / 38540], Loss : 0.9966099858283997\n",
            "Epoch [3 / 3],Step [29600 / 38540], Loss : 1.0830100774765015\n",
            "Epoch [3 / 3],Step [29700 / 38540], Loss : 1.072685718536377\n",
            "Epoch [3 / 3],Step [29800 / 38540], Loss : 0.9945089221000671\n",
            "Epoch [3 / 3],Step [29900 / 38540], Loss : 1.0383203029632568\n",
            "Epoch [3 / 3],Step [30000 / 38540], Loss : 1.0453288555145264\n",
            "Epoch [3 / 3],Step [30100 / 38540], Loss : 1.1310715675354004\n",
            "Epoch [3 / 3],Step [30200 / 38540], Loss : 0.9924121499061584\n",
            "Epoch [3 / 3],Step [30300 / 38540], Loss : 1.129739761352539\n",
            "Epoch [3 / 3],Step [30400 / 38540], Loss : 1.0617024898529053\n",
            "Epoch [3 / 3],Step [30500 / 38540], Loss : 1.0865436792373657\n",
            "Epoch [3 / 3],Step [30600 / 38540], Loss : 1.0118026733398438\n",
            "Epoch [3 / 3],Step [30700 / 38540], Loss : 0.9488720297813416\n",
            "Epoch [3 / 3],Step [30800 / 38540], Loss : 0.9293144941329956\n",
            "Epoch [3 / 3],Step [30900 / 38540], Loss : 1.047597885131836\n",
            "Epoch [3 / 3],Step [31000 / 38540], Loss : 1.1053589582443237\n",
            "Epoch [3 / 3],Step [31100 / 38540], Loss : 1.021244764328003\n",
            "Epoch [3 / 3],Step [31200 / 38540], Loss : 1.0355987548828125\n",
            "Epoch [3 / 3],Step [31300 / 38540], Loss : 1.0085690021514893\n",
            "Epoch [3 / 3],Step [31400 / 38540], Loss : 1.1493088006973267\n",
            "Epoch [3 / 3],Step [31500 / 38540], Loss : 1.0271472930908203\n",
            "Epoch [3 / 3],Step [31600 / 38540], Loss : 1.0410573482513428\n",
            "Epoch [3 / 3],Step [31700 / 38540], Loss : 0.9900831580162048\n",
            "Epoch [3 / 3],Step [31800 / 38540], Loss : 1.1141777038574219\n",
            "Epoch [3 / 3],Step [31900 / 38540], Loss : 1.0431325435638428\n",
            "Epoch [3 / 3],Step [32000 / 38540], Loss : 1.0062309503555298\n",
            "Epoch [3 / 3],Step [32100 / 38540], Loss : 0.9723737835884094\n",
            "Epoch [3 / 3],Step [32200 / 38540], Loss : 1.139764666557312\n",
            "Epoch [3 / 3],Step [32300 / 38540], Loss : 1.056297779083252\n",
            "Epoch [3 / 3],Step [32400 / 38540], Loss : 1.0005091428756714\n",
            "Epoch [3 / 3],Step [32500 / 38540], Loss : 0.9390702843666077\n",
            "Epoch [3 / 3],Step [32600 / 38540], Loss : 1.00484299659729\n",
            "Epoch [3 / 3],Step [32700 / 38540], Loss : 1.12154221534729\n",
            "Epoch [3 / 3],Step [32800 / 38540], Loss : 0.9691923260688782\n",
            "Epoch [3 / 3],Step [32900 / 38540], Loss : 1.0286067724227905\n",
            "Epoch [3 / 3],Step [33000 / 38540], Loss : 1.0324633121490479\n",
            "Epoch [3 / 3],Step [33100 / 38540], Loss : 0.9616773724555969\n",
            "Epoch [3 / 3],Step [33200 / 38540], Loss : 1.0228674411773682\n",
            "Epoch [3 / 3],Step [33300 / 38540], Loss : 1.142361044883728\n",
            "Epoch [3 / 3],Step [33400 / 38540], Loss : 0.9912844896316528\n",
            "Epoch [3 / 3],Step [33500 / 38540], Loss : 1.028717041015625\n",
            "Epoch [3 / 3],Step [33600 / 38540], Loss : 0.9793154001235962\n",
            "Epoch [3 / 3],Step [33700 / 38540], Loss : 0.9348794221878052\n",
            "Epoch [3 / 3],Step [33800 / 38540], Loss : 1.0260720252990723\n",
            "Epoch [3 / 3],Step [33900 / 38540], Loss : 0.906489908695221\n",
            "Epoch [3 / 3],Step [34000 / 38540], Loss : 1.0835052728652954\n",
            "Epoch [3 / 3],Step [34100 / 38540], Loss : 1.049026370048523\n",
            "Epoch [3 / 3],Step [34200 / 38540], Loss : 1.0244048833847046\n",
            "Epoch [3 / 3],Step [34300 / 38540], Loss : 1.1022295951843262\n",
            "Epoch [3 / 3],Step [34400 / 38540], Loss : 1.010313868522644\n",
            "Epoch [3 / 3],Step [34500 / 38540], Loss : 1.0239489078521729\n",
            "Epoch [3 / 3],Step [34600 / 38540], Loss : 1.1555492877960205\n",
            "Epoch [3 / 3],Step [34700 / 38540], Loss : 1.0962026119232178\n",
            "Epoch [3 / 3],Step [34800 / 38540], Loss : 1.0538135766983032\n",
            "Epoch [3 / 3],Step [34900 / 38540], Loss : 1.0268723964691162\n",
            "Epoch [3 / 3],Step [35000 / 38540], Loss : 1.2061810493469238\n",
            "Epoch [3 / 3],Step [35100 / 38540], Loss : 1.0389328002929688\n",
            "Epoch [3 / 3],Step [35200 / 38540], Loss : 1.0698966979980469\n",
            "Epoch [3 / 3],Step [35300 / 38540], Loss : 1.0188636779785156\n",
            "Epoch [3 / 3],Step [35400 / 38540], Loss : 1.068220615386963\n",
            "Epoch [3 / 3],Step [35500 / 38540], Loss : 1.1025989055633545\n",
            "Epoch [3 / 3],Step [35600 / 38540], Loss : 1.1470024585723877\n",
            "Epoch [3 / 3],Step [35700 / 38540], Loss : 1.0681489706039429\n",
            "Epoch [3 / 3],Step [35800 / 38540], Loss : 0.976093590259552\n",
            "Epoch [3 / 3],Step [35900 / 38540], Loss : 1.0913084745407104\n",
            "Epoch [3 / 3],Step [36000 / 38540], Loss : 1.0774801969528198\n",
            "Epoch [3 / 3],Step [36100 / 38540], Loss : 1.054729700088501\n",
            "Epoch [3 / 3],Step [36200 / 38540], Loss : 1.1205326318740845\n",
            "Epoch [3 / 3],Step [36300 / 38540], Loss : 1.0212987661361694\n",
            "Epoch [3 / 3],Step [36400 / 38540], Loss : 1.0995776653289795\n",
            "Epoch [3 / 3],Step [36500 / 38540], Loss : 1.0553847551345825\n",
            "Epoch [3 / 3],Step [36600 / 38540], Loss : 1.056194543838501\n",
            "Epoch [3 / 3],Step [36700 / 38540], Loss : 1.005365252494812\n",
            "Epoch [3 / 3],Step [36800 / 38540], Loss : 0.9553279876708984\n",
            "Epoch [3 / 3],Step [36900 / 38540], Loss : 0.9539840221405029\n",
            "Epoch [3 / 3],Step [37000 / 38540], Loss : 1.0472924709320068\n",
            "Epoch [3 / 3],Step [37100 / 38540], Loss : 0.9176805019378662\n",
            "Epoch [3 / 3],Step [37200 / 38540], Loss : 1.0114811658859253\n",
            "Epoch [3 / 3],Step [37300 / 38540], Loss : 0.9617001414299011\n",
            "Epoch [3 / 3],Step [37400 / 38540], Loss : 1.018867015838623\n",
            "Epoch [3 / 3],Step [37500 / 38540], Loss : 1.0601993799209595\n",
            "Epoch [3 / 3],Step [37600 / 38540], Loss : 0.9910222291946411\n",
            "Epoch [3 / 3],Step [37700 / 38540], Loss : 1.059054970741272\n",
            "Epoch [3 / 3],Step [37800 / 38540], Loss : 1.132336139678955\n",
            "Epoch [3 / 3],Step [37900 / 38540], Loss : 1.1261881589889526\n",
            "Epoch [3 / 3],Step [38000 / 38540], Loss : 1.0270661115646362\n",
            "Epoch [3 / 3],Step [38100 / 38540], Loss : 0.9829904437065125\n",
            "Epoch [3 / 3],Step [38200 / 38540], Loss : 1.0270401239395142\n",
            "Epoch [3 / 3],Step [38300 / 38540], Loss : 1.1023638248443604\n",
            "Epoch [3 / 3],Step [38400 / 38540], Loss : 1.1076732873916626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.analogic_test(word2idx[\"fast\"], word2idx[\"faster\"], word2idx[\"slow\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EPzmyXXosXFg",
        "outputId": "2387f233-5078-4061-8ea4-5aa85a0f4792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'slow'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.analogic_test(word2idx[\"man\"], word2idx[\"woman\"], word2idx[\"king\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AZy1tgvhC2bz",
        "outputId": "d0331491-0956-43ff-d99d-be8fdb3d0f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'king'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.similar_words(word2idx[\"work\"], 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKsYUUHjubhp",
        "outputId": "4a80ac0c-f09d-4fef-980f-dfe679b48d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('skills', tensor(0.9882, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('their', tensor(0.9858, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('teaching', tensor(0.9857, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('adults', tensor(0.9854, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('person', tensor(0.9853, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('appropriate', tensor(0.9850, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('emotional', tensor(0.9849, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('subtle', tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('concepts', tensor(0.9848, device='cuda:0', grad_fn=<DivBackward0>)),\n",
              " ('intense', tensor(0.9846, device='cuda:0', grad_fn=<DivBackward0>))]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aChgxri2udUq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
